\documentclass[a4paper]{article}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
\usepackage[german]{babel}

\usepackage{tikz}
\usetikzlibrary{automata, positioning}

\pdfminorversion=7
\pdfsuppresswarningpagegroup=1

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\beh}{\textit{Behauptung. }}

\setlength{\parindent}{0pt}

\begin{document}

\begin{titlepage}
	\begin{center}
		\vspace*{1cm}

		\textbf{Mathematische Modellierung}

		\vspace{0.5cm}
		\section*{
			Notizen für die Klausur
		}

		\vspace{1.5cm}

		\textbf{Bent Müller (7302332)}

		\vfill

		\vspace{0.8cm}


		Fachbereich Mathematik\\
		Universität Hamburg\\
		Deutschland\\
		20.08.2021

	\end{center}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak

\section{Cheatsheet}

\subsection{Reihen}

\begin{itemize}
	\item Taylorreihen-Entwicklung
	\[
		T_{n} ( f(x; a) ) = 
		\sum_{k=0}^{n} \frac{ f ^{(k)} (a) }{ k! } (x - a) ^{k}
		\quad \text{ mit }
	\] 
	\[
		f ^{(k)},
		\text{ $k$-te Ableitung von $f$; } \quad
		a,
		\text{ Entwicklungspunkt }
	\] 
	\item Exponentialreihe
	\[
		z \in \mathbb{C}: \qquad
		e ^{z} = \sum_{k=0}^{\infty} \frac{ z ^{k} }{ k! }
	\] 
	\item Geometrische Reihe
		\[
		| x | < 1: \qquad
		\sum_{k=0}^{\infty} x ^{k} = \frac{ 1 }{ 1 - x }
		\] 
\end{itemize}

\subsection{Ableitungsregeln}
\begin{itemize}
	\item Produktregel
		\[
			(g(x) \cdot f(x))' = 
			(g(x))' f(x) +
			(f(x))' g(x)
		\] 
	\item Kettenregel
		\[
		(f(g(x)))' =
		g' (x) \cdot f' (g(x))
		\] 
	\item Quotientenregel
	\[
		\left(
			\frac{ f(x) }{ g(x) }
		\right) '
		=
		\frac{ f' (x) g(x) - f(x) g' (x) }{ g ^2 (x) }
	\] 
\end{itemize}

\subsection{Integrationstechniken}
\begin{itemize}
	\item Partielle Integration
		\begin{align*}
			\int_{a}^{b} f' (x) g(x) dx
			= - \int_{a}^{b} f(x) g' (x) dx 
			+ \left[
				f(x) g(x)
			\right]_a^b \quad & \text{ (bestimmt) } \\
			\int f'(x) g(x) dx = - \int f(x) g'(x) dx
			+ f(x) g(x) \quad & \text{ (unbestimmt) }
		\end{align*}
	\item Substitutionsregel
		\begin{gather*}
			\int_{a}^{b} \varphi' (x) f( \varphi(x) ) dx
			=
			\int_{\varphi(a)}^{\varphi(b)} f(u) du \\
				u := \phi (x)
				\Rightarrow \frac{ du }{ dx } = \phi' (x)
				\Rightarrow dx = \frac{ du }{ d \phi(x) } \\
				\Rightarrow
				\int_{a}^{b} \varphi' (x) f( \varphi(x) ) dx
				 = \int_{\phi (a)}^{\phi(b)} \phi' (x) f(u)
				\frac{ du }{ \phi' (x) } 
				 = \int_{\varphi(a)}^{\varphi(b)} f(u) du
		\end{gather*}
\end{itemize}

\subsection{Trigonometrische Identitäten}
\begin{gather}
	\sin (x_1 + x_2) =
	\sin (x_1) \cos (x_2) + 
	\sin (x_2) \cos (x_1) \\
	\cos (x_1 + x_2) = 
	\cos (x_1) \cos(x_2) - 
	\sin (x_1) \sin(x_2) \\
	\sin ^2 (x) = \frac{ 1 }{ 2 } \left(
		1 - \cos (2x)
	\right), \qquad
	\cos ^2 (x) = \frac{ 1 }{ 2 } \left(
		1 + \cos (2x)
	\right) \\
	\sin (x_1) + \sin (x_2)
	= 2 \cdot \sin \left(
		\frac{ x_1 + x_2 }{ 2 }
	\right) \cdot \cos \left(
		\frac{ x_1 - x_2 }{ 2 }
	\right) 
\end{gather}

\subsection{Lineare Algebra - Basics}
\begin{itemize}
	\item Determinante 2x2 Matrix
		\[
		\det \begin{pmatrix} 
			a & b \\
			c & d \\
		\end{pmatrix} 
		= ad - bc
		\] 
	\item Charakteristisches Polynom 2x2 Matrix
		\[
			P_\lambda (A)
			= \det (A - \lambda \cdot I) =
			\det \begin{pmatrix} 
				a - \lambda & b \\
				c & d - \lambda \\
			\end{pmatrix} =
			(a - \lambda) (d - \lambda) - bc
		\] 
	\item Eigenwerte 2x2 Matrix
		(Nullstellen des charakteristischen Polynoms):
		\begin{gather*}
			(a - \lambda) (d - \lambda) - bc = 0
			\Leftrightarrow 
			\lambda ^2 - \lambda (a + d) + ad - bc = 0 \\
			\Rightarrow
			\lambda = \frac{ a+d \pm \sqrt{(a+d) ^2 -4 (ad -bc)} }{ 2 } \\
			= \frac{ 1 }{ 2 } \left(
				a + d \pm \sqrt{
					a ^2 + d ^2 - 2 ad + 4 bc
				} 
			\right) 
		\end{gather*}
	\item abc-Formel (= Quadratische Formel)
		\[
			a x ^2 + b x + c = 0
			\Leftrightarrow 
			x = \frac{ -b \pm \sqrt{b ^2 - 4 ac} }{ 2a }
		\] 
\end{itemize}

\subsection{Landau-Symbole}
Für $x \to x_0$:
\begin{align*}
	f(x) = o(g(x))
	&\Leftrightarrow \frac{ f(x) }{ g(x) } \to 0 \\
	f(x) = O(g(x))
	&\Leftrightarrow \frac{ f(x) }{ g(x) } \text{ beschränkt } \\
	f(x) = \text{ord}(g(x))
	&\Leftrightarrow 
	\frac{ f(x) }{ g(x) } = O(1) \text{ und }
	\frac{ g(x) }{ f(x) } = O(1)
\end{align*}

\pagebreak

\section{Funktionsapproximation}

\subsection{Rationale Interpolation}

Funktioniert ähnlich wie normale Interpolation, mit dem entscheidenden
Unterschied, dass wir hier einen \textbf{Bruch} von Polynomen benutzen.

\[
	R_{m, n} (x) := \frac{ 
		P_m (x)
	}{ Q_n (x) } \text{ mit }
	P_m (x) := \sum_{k=0}^{m} a_k x^{k}, \;
	Q_n (x) := \sum_{k=0}^{n} b_k x^{k}, \;
\] 

\begin{itemize}
	\item Polynomgrade $m$ und $n$ sind gegeben
	\item Es soll gelten für bekannte $x_i$: ($f$ ist die zu 
		interpolierende Funktion)
		\[
			f(x_0) = R_{m, n} (x_0), ...,
			f(x_1) = R_{m, n} (x_1)
		\] 
	\item $m+n+2$ freie Koeffizienten
	\item Oft wird normiert durch $b_0 = 1$
	\item $m+n \; (=s)$ = Anzahl Freiheitsgrade (= Anzahl Interpolationsbedingungen)
	\item Wir erhalten lineares homogenes Gleichungssystem:
		\[
			P_m (x_i) - f(x_i) Q_n(x_i) = 0
			\qquad i \in \{
				0, ..., m+n
			\} 
		\] 
	\item Dieses LGS hat immer eine nicht-triviale Lösung.
	\item Es kann passieren, dass es unerreichbare Punkte gibt, für solche
		braucht man mehr Freiheitsgrade.
\end{itemize}

\subsection{Ausgleichsrechnung mit rationalen Funktionen}

Hier schauen wir uns Kriterien für die Bestimmung der Koeffizienten an.
Geläufig ist das Gaußsche Prinzip der kleinsten 
\textbf{Summe der Fehlerquadrate}.
\\

Problem ist nämlich, dass man oft mehr Beobachtungen zur Interpolation
hat als man der rationalen Funktion Freiheitsgrade geben möchte.
\\

Zur Notation:
\begin{itemize}
	\item $b_0 = 1$ (normiert)
	\item $(x_0, f_0), \; ... \;, (x_s, f_s)$
		ist die Folge an Beobachtungen
	\item $m + n + 1 < s =$ Anzahl an Beobachtungen
\end{itemize}

\subsubsection{Kleinste Summe von Fehlerquadraten}

\[
\rho \left(
	a_0, a_1, ..., a_m,
	b_1, b_2, ..., b_n
\right) :=
\sum_{i=0}^{s} \left[
	P_m (x_i) - f(x_i) Q_n (x_i)
\right] ^2
\] 

\begin{itemize}
	\item Im Fall $m+n+1 = s$ finden wir die eindeutige Lösung 
		(das LGS von vorher).
	\item Ansonsten: Minimum der oberen Gleichung finden.
\end{itemize}

Hierfür müssen wir den Gradienten der Fehlerquadrate gleich $0$ setzen.
\begin{align*}
	& \nabla
		\rho \left(
			a_0, a_1, ..., a_m,
			b_1, b_2, ..., b_n
		\right) 
		\text{ (Gradient) }
		\\
	&= \left(
		\frac{ \partial \rho }{ \partial a_0 },
		\frac{ \partial \rho }{ \partial a_1 },
		...,
		\frac{ \partial \rho }{ \partial a_m },
		\frac{ \partial \rho }{ \partial b_1 },
		\frac{ \partial \rho }{ \partial b_1 },
	\right) 
\end{align*}

Wir können diese Gleichung dann weiter auflösen und erhalten am Ende durch
umsortieren ein LGS, welches wie folgt aussieht.

\begin{align*}
	& \begin{pmatrix} 
		s+1 &
		\sum_{i} x_i &
		\cdots &
		\sum_{i} x_i ^{m} &
		- \sum_{i} f_i x_i &
		\cdots &
		- \sum_{i} f_i x_i ^{n} \\[1em]
		\sum_{i} x_i &
		\sum_{i} x_i ^2 &
		\cdots &
		\sum_{i} x_i ^{m+1} &
		- \sum_{i} f_i x_i ^2 &
		\cdots &
		- \sum_{i} f_i x_i ^{n+1} \\[1em]
		\vdots &
		\vdots &
		\ddots &
		\vdots &
		\vdots &
		\ddots &
		\vdots \\[1em]
		\sum_{i} x_i ^{m} &
		\sum_{i} x_i ^{m+1} &
		\cdots &
		\sum_{i} x_i ^{2m} &
		- \sum_{i} f_i x_i ^{m+1} &
		\cdots &
		- \sum_{i} f_i x_i ^{m+n} \\[1em]
		\sum_{i} f_i x_i &
		\sum_{i} f_i x_i ^2 &
		\cdots &
		\sum_{i} f_i x_i ^{m+1} &
		- \sum_{i} f_i ^2 x_i ^2 &
		\cdots &
		- \sum_{i} f_i ^2 x_i ^{n+1} \\[1em]
		\sum_{i} f_i x_i ^2 &
		\sum_{i} f_i x_i ^3 &
		\cdots &
		\sum_{i} f_i x_i ^{m+2} &
		- \sum_{i} f_i ^2 x_i ^3 &
		\cdots &
		- \sum_{i} f_i ^2 x_i ^{n+2} \\[1em]
		\vdots &
		\vdots &
		\ddots &
		\vdots &
		\vdots &
		\ddots &
		\vdots \\[1em]
		\sum_{i} f_i x_i ^n &
		\sum_{i} f_i x_i ^{n+1} &
		\cdots &
		\sum_{i} f_i x_i ^{m+n} &
		- \sum_{i} f_i ^2 x_i ^{n+1} &
		\cdots &
		- \sum_{i} f_i ^2 x_i ^{2n} \\[1em]
	\end{pmatrix} 
	\begin{pmatrix} 
		a_0 \\[1em]
		a_1 \\[1em]
		\vdots \\[1em]
		a_m \\[1em]
		b_1 \\[1em]
		b_2 \\[1em]
		\vdots \\[1em]
		b_n \\[1em]
	\end{pmatrix} \\
	&= \left(
		\sum_i f_i, \;
		\sum_i f_i x_{i}, \;
		\cdots, \;
		\sum_i f_i x_{i} ^{m}, \;
		\sum_i f_i ^2 x_{i}, \;
		\cdots, \;
		\sum_i f_i ^2 x_{i} ^{n}, \;
	\right) ^{T}
\end{align*}

\subsection{Pad\'e Approximation}

Idee: Bestimme rationale Funktion, sodass die Potenzreihen-Entwicklung (PRE)
soweit wie möglich mit der PRE von der zu approximierenden Funktion übereinstimmt.
\\

Oft wird hier als PRE die Taylorreihe benutzt.


\subsubsection{Pad\'e Approximation - Definition}

\begin{align*}
	& R_{m, n} (x) \text{ ist Pad\'e Approximierende } \\
	& \Leftrightarrow \forall k \in \{
		0, 1, ..., m+n
	\} : 
	\frac{ d ^{k} }{ d x ^{k} } R_{m, n} (0)
	=
	\frac{ d ^{k} }{ d x ^{k} } f (0) \\
	& \Leftrightarrow \text{ jeweils $k$-ten Ableitungen stimmen überein }
\end{align*}

Wir erhalten daraus folgende Gleichungen:
\begin{align*}
	& \sum_{j=0}^{k} b_j c_{k-j} = a_k
	\text{ für } k \in \{
		0, ..., m
	\} \text{ und } \\
	& \sum_{j=0}^{k} b_j c_{m-j+k} = 0
	\text{ für } k \in \{
		1, ..., n
	\}  \\
	& \text{ und wieder } b_0 = 1
\end{align*}


\section{Optimierung}

\subsection{Geometrische Lösung linearer Optimierung im $\R ^2$}

TODO: Einfache Skizze / Anleitung zur Lösung solche aufgaben muss hier angefertigt
werden.

\subsection{lineare Optimierung im $\R ^{n}$}

\begin{itemize}
	\item Bei $\max$-Optimierungsaufgaben die Zielfunktion mit $-1$
		multiplizieren und Minimum berechnen.
\end{itemize}

\subsubsection{Beispiel Schuhfabrik}

Jeden Monat stehen zur Verfügung:

\begin{itemize}
	\item $8000$ Stunden Herstellungszeit
	\item $2000$ Stunden Maschinenzeit
	\item $4500\; dm ^2$ Leder
\end{itemize}

Pro Schuh $16$ Euro für Damenschuh und $32$ Euro für Herrenschuh.
\\

Stelle Nebenbedingung auf:

\begin{align*}
	20 x_1 + 10 x_2 & \leq 8000 \\
	4 x_1 + 5 x_2 & \leq 2000 \\
	6 x_1 + 15 x_2 & \leq 4500 \\
	x_1 & \geq 0 \\
	x_2 & \geq 0 & \\
\end{align*}

Maximiere Zielfunktion $Z(x_1, x_2) = 16 x_1 + 32 x_2 \rightarrow \max !$.

\section{Dynamische Systeme (Prozesse)}

Beschreibung der Zeit $t$ und aller möglichen Zustände, einem sog.
Zustandsraum $X$.

\subsection{Deterministische zeitdiskrete dynamische Systeme}

Modell:

\[
	x(t+1) = F(x(t)) \text{ oder } x(t+1) = x(t) + f(x(t))
	\text{ mit } t \in \N_0
\] 

\subsubsection{Fixpunkte}

\begin{align*}
	& x ^{*} \in X \text{ ist Fixpunkt } \\
	& \Leftrightarrow x ^{*} = F ( x ^{*} ) \\
	& \Leftrightarrow x ^{*} \text{ bleibt auf sich sitzen }
\end{align*}

\subsubsection{Differenzengleichungen}


\begin{align*}
	& f(t, x(t), x(t+1), ..., x(t+k)) = 0 \qquad
	\forall t \in \mathbb{N} \\
	& \text{ mit } f: \N \times D^{k+1} \rightarrow \mathbb{K}
	\text{ und } D \subseteq \mathbb{K}
\end{align*}

\begin{itemize}
	\item $f$ gegeben und $x$ gesucht
	\item \textbf{autonom} $\Leftrightarrow$ 
		$f$ hängt nicht explizit von $t$ ab.
	\item $k$ ist \textbf{Ordnung} oder \textbf{Grad} 
	\item $x: \N \rightarrow D$ heißt \textbf{Lösung}
\end{itemize}

Differenzengleichungen als diskrete dynamische Systeme:
\[
	x(t+k) = \tilde{f} \left(
		t, x(t), ..., x(t+k-1)
	\right) \qquad
	\forall t \in \mathbb{N} 
\] 

\subsubsection{Lineare diskrete dynamische Systeme}

\begin{align*}
	x(t+1) = A(t) x(t) + u(t)
	\qquad \qquad & \text{ (inhomogen) } \\
	x(t+1) = A(t) x(t)
	\qquad \qquad & \text{ (homogen) }
\end{align*}

Dabei gilt:

\begin{itemize}
	\item $(A(t))_{t \in \mathbb{N}}$
		ist Folge von Matrizen $A(t) \in \R ^{n, n}$
	\item $(u(t))_{t \in \mathbb{N}}$ ist Folge von Vektoren 
		$u(t) \in \R ^{n}$
\end{itemize}

Über Linearisierung Approximation von nichtlinearen Systemen
\\

\subsubsection{Übergangsmatrix}

Für $s, t \in \N, s \leq t$ ist:

\[
	\Phi(t, s) := 
	\begin{cases}
		I \text{ (Einheitsmatrix)}, 
		& \text{ falls } s = t \\
		A(t-1) A(t-2) ... A(s),
		& \text{ falls } s < t
	\end{cases}
\] 

Ist die Übergangsmatrix von $s$ nach $t$.
\\

TODO: Anfangswertaufgabe hier und inhomogenes System,
\\

TODO: Lösung inhomogene und homogen systems hier Satz 5.1
Fundamentalmatrix

\subsubsection{Zeitinvariante lineare Systeme}

\[
	x(t+1) = A x(t)
	\qquad \text{ (Matrix konstant) }
\] 

Lösung über Eigenwerte (-vektoren):
\begin{align*}
	v \in \R ^{n}, v \ne 0 \qquad
	& \text{ Eigenvektor mit } \\
	\lambda \in \R \qquad
	& \text{ Eigenwert von } A
	\quad ( \Leftrightarrow  Av = \lambda v ) \\
	\Rightarrow y(t) = \lambda ^{t} v \qquad
	& \text{ ist Lösung des Systems }
\end{align*}

\subsubsection{Ähnlichkeitstransformation von Matrizen}
\begin{align*}
	& A, B \in \mathbb{K} ^{n, n} \text{ sind ähnlich } \\
	& \Leftrightarrow \exists
		S \in \mathbb{K} ^{n,n},\; S \text{ invertierbar} :
		B = S ^{-1} A S
\end{align*}

\underline{Jede} Matrix $A \in \mathbb{C} ^{n,n}$ ist ähnlich
zu einer Matrix in Jordanscher Normalform.
\\

TODO: Jordansche Normalform Kapitel 5.4 im Skript

\subsubsection{Langzeitverhalten der Lösung}
\begin{align*}
	& A \in \mathbb{C} ^{n,n}, \lambda_1 \text{ betragsgrösster Eigenwerte } \\
	& \text{ zu } \lambda_1 : v_1 \text{ Rechtseigenvektor }, q_1
	\text{ Linkseigenvektor } \\
	& \Leftrightarrow A v_1 = \lambda_1 v_1, q_1 ^{H} A = \lambda_1 q_1 ^{H} \\
	&\Rightarrow \forall x(t) \text{ Lösung des Systems}:
	\lim_{t \to \infty} \frac{ x(t) }{ \lambda_1 ^{t} }
	= (q_1 ^{H} x(0)) v_1
\end{align*}

$q_1 ^{H}$ ist komplex konjugierte von $q_1$.

\subsubsection{Positive lineare Systeme}
\[
	A = (a_{ij}):
	A \geq (>) 0 \Leftrightarrow \forall (i, j): a_{ij} \geq (>) 0
\] 

TODO: Satz von Perron-Frobenius (Satz 5.5)

\subsubsection{Satz über Nullstellen von reellen Polynomen}
\begin{align*}
	& p = \lambda ^{n} - \left(
		d_1 \lambda ^{n-1} + \cdots + d_{n-1} \lambda + d_n
	\right) \\
	& d_1, ..., d_n \geq 0 \text{ und } 
	\exists k: d_k > 0 \\
	&\Rightarrow \exists \lambda_1 \text{ reell positive einfache Nullstelle}: \\
	& \qquad \lambda_1 \geq | \lambda |, 
	\forall \lambda \text{ anderen Nullstellen von } p \\
	& \\
	&\Rightarrow \text{ggT} ( k ) = 1, \text{ wobei }
	k \text{ Indite von } d_k > 0 \\
	& \qquad \Rightarrow \lambda_1 > | \lambda |, 
	\forall \lambda \text{ anderen Nullstellen von } p
\end{align*}

\subsection{Stabilität dynamischer Systeme}
$x(t)$ sei Lösung:

\begin{itemize}
	\item $\Rightarrow \{
			x(0), x(1), ...
		\} $ heißt \textbf{Bahn} oder \textbf{Orbit} von $x(t)$
	\item $x(t)$ heisst \textbf{stabil}:
		\[
		\forall \varepsilon > 0, \exists \delta :
		\left(
			(
				\forall y(t) \text{ Lösung}, \| y(0) - x(0) \| < \delta
			)
			\Rightarrow \forall t \in \mathbb{N}:
			\| y(t) - x(t) \| < \varepsilon
		\right) 
		\] 
	\item $x(t)$ nicht stabil $\Leftrightarrow$ $x(t)$ \textbf{instabil} 
	\item $x(t)$ heisst \textbf{attraktiv}:
		\[
		\exists \delta : \left(
			(
				\forall y(t) \text{ Lösung}, \| y(0) - x(0) \| < \delta
			)
			\Rightarrow \lim_{t \to \infty} 
			\| y(t) - x(t) \| = 0
		\right) 
		\] 
	\item $x(t)$ heisst \textbf{asymptotisch stabil} 
		$\Leftarrow$ ($x(t)$ stabil und attraktiv)
	\item Umgekehrte Implikationen gelten hier \textbf{nicht}:
		\[
			\text{z.B.} \; x(t) \; \text{stabil} \nRightarrow
			\left(
				\forall \varepsilon > 0 \cdots
			\right) 
		\] 
\end{itemize}

\subsubsection{Stabilität linearer Systeme}

\begin{itemize}
	\item \underline{eine} stabile Lösung existiert $\Rightarrow$ \underline{alle}
		Lösungen sind stabil.
\end{itemize}
\begin{align}
	x(t+1) &= A(t) x(t) + b(t), \qquad x(0) = x_0 \\
	x(t+1) &= A(t) x(t)
\end{align}

Folgende Aussagen sind \underline{äquivalent}:

\begin{itemize}
	\item Alle Lösungen des inhomogenen Systems (1) sind stabil.
	\item Eine Lösung des inhomogenen Systems (1) ist stabil.
	\item Die Nulllösung ($x(t) = 0$) des homogenen Systems (2) ist stabil.
\end{itemize}

\subsubsection{Stabilität nichtlinearer Systeme}
Geht im Allgemeinen nicht, also
Stabilität in Fixpunkten untersuchen oder
Periodische Punkte finden.

\begin{itemize}
	\item $\overline{x}$ heisst \textbf{periodischer Punkt}, wenn:
		\[
		\exists p \in \mathbb{N}:
		F ^{p} (\overline{x})
		\text{ und }
		F ^{t} (\overline{x}) \neq \overline{x}
		\text{ für } t \in \{
			1, ..., p-1
		\} 
		\] 
	\item $p$ heisst \textbf{Periode}  von $\overline{x}$
	\item $x$ Lösung heisst \textbf{Gleichgewichtspunkt}, wenn
		$\forall t \in \mathbb{N}: x(t) = x ^{*}$
		mit $x ^{*}$ Fixpunkt ist.
	\item $x ^{*}$ Fixpunkt ist periodischer Punkt mit $p = 1$
	\item Für $\overline{x}$ periodisch mit Periode $p$
		$\Rightarrow \; \overline{x}$ ist GGP von $F ^{p}$
	\item Jeder GGP von $F ^{p}$ ist periodischer Punkt von $F$ mit
		einem Teiler von $p$ als Periode.
\end{itemize}

Stabilitätsaussage bei \textbf{stetig differenzierbarem} $f$ (bzw. $F$):
\[
	x(t+1) = f(x(t))
\] 

$x ^{*}$ GGP $\Rightarrow$ $x ^{*}$ ist
\begin{itemize}
	\item asymptotisch stabil, falls $| f' (x ^{*}) | < 1$
	\item instabil, falls $| f'(x ^{*}) | > 1$
\end{itemize}

\subsubsection{Asymptotisch stabile Matrix}
\begin{align*}
	& A \in \R ^{n, n} \text{ heisst asymptotisch stabil } \\
	&\Leftrightarrow 0 \text{ ist GGP von } x(t+1) = A x(t) \\
	&\Leftrightarrow \forall x \in \R \lim_{t \to \infty} A ^{t} x = 0
\end{align*}

\subsubsection{Kriterium für asymptotische Stabilität}
Bei $F$ in $x ^{*}$ (einem Fixpunkt) differenzierbar:
\begin{align*}
	& M \subseteq \R ^{n}, F: M \rightarrow M,
	x ^{*} \text{ innerer Punkt von } M: \\
	& \textbf{DF} (x ^{*}) \;\; (\text{Jacobi Matrix}) \text{ asymptotisch stabil} \\
	&\Rightarrow x ^{*} \text{ asymptotisch stabil}
\end{align*}

Im vorigen Kriterium steht aber nur ein lineares System, also müssen
wir für die Stabilität des Systems nur die Eigenwerte der Jacobi-Matrix
prüfen. (Schauen ob diese jeweils $</> 1$ sind)

\subsubsection{Stabilität eines inneren Orbits }

\begin{align*}
	& M \subseteq \R ^{n}, F: M \rightarrow M \text{ stetig } \\
	& \gamma := \{
		x_0, ..., x_{p-1}
	\} \text{ im Inneren von $M$ liegendes $p$-periodisches Orbit } \\
	& \\
	& \textbf{DF}^{p} (x_0) =
	\textbf{DF} (x_{p-1})
	\textbf{DF} (x_{p-2})
	\cdots
	\textbf{DF} (x_1)
	\textbf{DF} (x_0) \text{ (Jacobi von $F ^{p}$ ) }
	\\
	& \text{besitzt nur Eigenwerte betragsmässig} < 1 \\
	&\Rightarrow \gamma \text{ asymptotisch stabil } \\
	& \\
	& \textbf{DF}^{p} \text{ besitzt einen Eigenwert betragsmässig}>1  \\
	&\Rightarrow \gamma \text{ ist instabil }
\end{align*}

TODO: Unterschied zwischen Orbit und Lösung präzisieren

\subsection{Dynamische stochastische Prozesse}

\subsubsection{Entropie}
Entropie ist das Maß des Informationsgewinns beim Bekanntwerden eines
Ereignisses eines Zufallsexperimentes.

\subsubsection*{Definition - Entropie}
Ereignis $E$ hat Wahrscheinlichkeit $p$. Funktion $H(p)$ heisst \textbf{Entropie}
wenn folgende Axiome gelten:

\begin{itemize}
	\item $H(1) = 0$ (für $p = 1$ entsteht kein Informationsgewinn)
	\item $\forall p_1, p_2 \in (0, 1]: p_1 < p_2 \Rightarrow H(p_2) < H(p_1)$
	\item $H(p)$ ist stetig auf $(0, 1] \rightsquigarrow$ 
		kleine Ursache, kleine Wirkung
	\item $\forall p_1, p_2 \in (0, 1]: H(p_1 p_2) = H(p_1) + H(p_2)$
\end{itemize}

TODO: mehr über Entropie herausfinden und bessere Intuition ausarbeiten

\subsubsection{Approximative Entropie}
Versuch der Analyse von Entropie einer Zahlenfolge
\[
x = \left(
	x_1, ..., x_{n}
\right) 
\] 

\begin{enumerate}
	\item Wähle Genauigkeit $\varepsilon > 0$
	\item Betrachte Abschnitte $x_{i} ^{m} := (x_{i}, ..., x_{i+m-1})$
		der Länge $m$.
	\item Definiere Metrik 
		$d(x_{i} ^{m}, x_{j} ^{m}) := \max_{k\in [1, m]} \{
			| x_{i+k-1} - x_{j+k-1} |
		\} $
	\item Definiere Anteil der Übereinstimmungen 
		aller vorkommenden Folgen
		mit $x_{i} ^{m}$
		\[
			C_{i} ^{m} (\varepsilon)
			:= \frac{ 
				\text{Anzahl} \{
					j \in [1, n-m+1]:
					d \left(
						x_{i} ^{m}, x_{j} ^{m}
					\right) \leq \varepsilon
				\} 
			}{ n - m + 1 }
		\]
	\item Definiere Hilfsgrösse
		\[
			\phi_m (\varepsilon)
			:=
			\frac{ \sum_{i=1}^{n-m+1} \log (C_i ^{m}) }{ n-m+1 }
		\] 
	\item Definiere \textbf{Approximative Entropie}
		\begin{align*}
			& AE (m, \varepsilon, n) (x) := 
			\phi_m (x) - \phi_{m+1} (\varepsilon)
			\qquad \forall m \geq 1
			\\
			& AE(0, \varepsilon, n) (x) :=
			- \phi_1 (\varepsilon)
		\end{align*}
\end{enumerate}

\subsubsection*{$(m,n)$-Zufälligkeit binärer Folgen}
Eine binäre Folge $x$ mit Länge $n$ heisst $(m,n)$-zufällig, wenn
\[
	AE(m, \varepsilon, n) (x) = \max_{y} AE(m, \varepsilon, n)(y)
\] 
Das Maximum der $AE$ aller $2^{n}$ binären Folgen.
\\

Für zwei Folgen $x, y$ der Länge $n$ gilt:

\[
x \text{ zufälliger als } y 
\Leftrightarrow
\forall n \geq m \geq 0: \;
AE(m, \varepsilon, n) (x) \geq
AE(m, \varepsilon, n) (y)
\] 

\subsection{Grundbegriffe stochastischer Prozesse}
Folge von Zufallsvariablen die von einem Parameter
abhängen heisst stochastischer Prozess (SP):

\[
\{
	x(t) \; \vert \; t \in T
\} 
\] 

\begin{itemize}
	\item $T$ heisst \textbf{Parameterraum} 
	\item $x(t) \in Z$, $Z$ heisst \textbf{Zustandsraum} 
	\item $T$ diskret $\Rightarrow$ $\{
			x(t) \; \vert \; t \in T
	\} $ ist abzählbar
	\item $x \in \R ^{n}$ ist Wahrscheinlichkeitsverteilung
		$\Leftrightarrow \sum_{i=1}^{n} x_{i} = 1$
		und $x_{i} \geq 0$
\end{itemize}

\subsubsection{Markowketten}
\begin{itemize}
	\item Markowkette:
		\[
			P(x(t_{m+1}) = i_{m+1})
			\text{ hängt nur von $x(t_m)$ ab }
			\text{ (und nicht von $x(t_{m-1})...$) }
		\] 
	\item Zustandsvektor $x_{j} (t)$ beschreibt W. dass System
		sich zum Zeitpunkt $t$ in Zustand $j$ befindet.
	\item Übergangswahrscheinlichkeit (W. von $i$ nach $j$ zur Zeit $t_m$)
		\[
			p_{ij} (t_m , t_{m+1}) =
			P(x(t_{m+1}) = j \; \vert \; x(t_m) = i)
		\] 
	\item Markowkette \textbf{homogen} $\Leftrightarrow
		p_{ij}$ hängt nicht von der Zeit ab
	\item Übergangswahrscheinlichkeiten bilden Matrix $\mathbb{P} = (p_{ij})$
		mit:
		\[
		p_{ij} \geq 0 \text{ und }
		\sum_{j=1}^{n} p_{ij} = 1
		\] 
	\item Transponiert können wir die Kette als dynamisches System schreiben
		\[
			x(t+1) = \mathbb{P} ^{T} x(t)
		\] 
\end{itemize}

TODO: Stoppzeiten wiederholen hier

\subsubsection{Deterministische Interpretation von Markowketten}
\begin{align*}
	& A \in \R ^{n,n} \text{ ist stochastische Matrix } \\
	&\Leftrightarrow A \geq 0, \text{ \textbf{Spalten}summe } = 1 \\
	& \qquad \qquad \Leftrightarrow \sum_{i=1}^{n} p_{ij} = 1 \\
\end{align*}

\begin{itemize}
	\item Anstatt Wahrscheinlichkeiten werden Anteile modelliert
	\item Beispiel $\rightsquigarrow$ Aufenthaltsort eines Phosphat Moleküls im
		Phosphatkreislauf
	\item Lineare Systeme mit stochastischer Matrix heissen
		\textbf{Markowprozesse}.
\end{itemize}

\subsubsection{Langzeitverhalten Markowketten}
\begin{itemize}
	\item $x \in \R ^{n}$ eine Wahrscheinlichkeitsverteilung
		$\Rightarrow \mathbb{P} \cdot x$ auch WV \\
		mit $\mathbb{P}$ stochastische Matrix
		(bzw. transponierte Übergangsmatrix einer Markowkette)
	\item $\lambda_1 = 1$ ist Eigenwert der stochastischen Matrix
		$\mathbb{P} ^{T}$
		$\Rightarrow \forall \lambda$ anderen Eigenwerte
		$| \lambda | \leq 1$
	\item Markowkette heisst \textbf{regulär}
		$\Leftarrow \exists p \in \mathbb{N}: \left(
			\mathbb{P} ^{T}
		\right) ^{t} > 0$
	\item reguläre Markowketten haben immer den Eigenwert $1$
		mit einem Eigenvektor $y$ welcher eine WV ist.
		Alle anderen Eigenwerte (-vektoren) verschwinden
		wenn wir die Kette als dynamisches System darstellen
		(Eigenwerte $|\lambda|<1$).
\end{itemize}

\setcounter{equation}{0}

\subsection{Chaos - Pseudo Zufallszahlen}

\subsubsection{chaotische Abbildungen}
Eine Abbildung $f: M \rightarrow M$ heisst chaotisch, wenn:
\begin{align}
	& f \text{ topologisch transitiv }
	\Leftrightarrow \forall I, J \subseteq M: \exists k \in \mathbb{N}:
	f ^{k} (I) \cap J \ne \O
	\\
	& \text{ jede Umgebung von $x \in M$ enthält einen periodischen Punkt } 
	\text{ (liegen dich in $M$) }
	\\
	& \exists \zeta > 0: \forall x \in M
	, U \text{ Umgebung von } x:
	\exists y \in U, k \in \mathbb{N}:
	|f ^{k} (x) - f ^{k} (y) | > \zeta
\end{align}

\begin{itemize}
	\item (1) besagt, dass $f$ nach einiger Zeit zu allen Punkten
		gelangen wird.
	\item (2) sagt, dass jeder Punkt von $f$ unendlich oft besucht wird.
	\item (3) sagt, dass die Abbildung garantiert divergiert,
		also jeder Punkt egal wie nah am ursprünglichen $x$ irgendwann
		weit entfernt von $x$ sein wird.
\end{itemize}

\subsection{Gewöhnliche Differentialgleichungen}
\[
	F(x, u(x), u'(x), ..., u ^{(n)}) = 0
\] 
\begin{itemize}
	\item ist Differentialgleichungen $n$-ter Ordnung
	\item Anfangswertproblem heisst, wir haben einen Anfangswert gegeben,
		da wir sonst unendlich viele Lösungen erhalten. Alternativ
		setzen wir den Anfangswert einfach auf ein $x_0$, sodass wir
		die Allgemeine Lösung erhalten.
	\item Die DGL heisst \textbf{explizit}
		$\Leftarrow$ man kann nach $u ^{(n)} (x)$ auflösen
		\[
			u ^{(n)} (x) =
			f(
				x,
				u(x),
				u'(x),
				...,
				u ^{(n-1)} (x)
			)
		\] 
	\item nicht explizit heisst \textbf{implizit} 
	\item $\phi (x)$ heisst Lösung auf $I \subseteq \R \Leftarrow$
		\begin{align*}
			& \phi(x),
			\phi(x)',
			...,
			\phi(x) ^{(n)}
			\text{ existieren in } I \text{ und } \\
			&
			\forall x \in I
			\phi ^{(n)} (x) =
			f(
				x,
				\phi(x),
				\phi(x)',
				...,
				\phi ^{(n-1)} (x)
			)
		\end{align*}
	\item DGL heisst \textbf{gewöhnlich} $\Leftarrow$
		$u$ hängt nur von einer Variable ab ($x$)
	\item eine DGL heisst \textbf{linear} $\Leftarrow$
		$F$ ist linear in $x, u(x), u'(x) ..., u ^{(n)} (x)$
		\[
			a_n (x) y ^{(n)} +
			a_{n-1} (x) y ^{(n-1)} +
			... + 
			a_{0} (x) y
			= b(x)
		\] 
		$a$ kann von $x$ abhängen, es dürfen nur die Ableitungen
		z.B. nicht quadriert werden
\end{itemize}

\subsubsection{Welcher Typ Differentialgleichung?}

Welchen Typ von Differentialgleichung habe ich vorliegen?
\begin{enumerate}
	\item Separierbare Differentialgleichungen
		\[
			y' (x) = f(x) \cdot g(y), \qquad
			y(x_0) = y_0, \qquad
			g(y) \neq 0
		\] 
	\item Ähnlichkeitsdifferentialgleichungen
		\[
			y' (x) = f \left(
				\frac{ y }{ x }
			\right) 
		\] 
	\item lineare Differentialgleichungen erster Ordnung
		\[
			y' (x) + a(x) y(x) = b(x)
		\] 
	\item Bernoullische Differentialgleichungen
		\[
			y' (x) + a(x) y(x) + b(x) (y(x)) ^{\alpha} = 0,
			\qquad \alpha \in \R \setminus \{
				0, 1
			\} 
		\] 
	\item Riccatische Differentialgleichungen
		\[
			y' (x) + a(x) y(x) + b(x) y ^2 (x) = c(x), \qquad
			\text{ spez. Lsg. } y_p (x) \text{ bekannt }
		\] 
	\item Exakte Differentialgleichungen
		\[
			g(x, y(x)) + h(x, y(x)) y' (x) = 0
		\] 
\end{enumerate}

\subsubsection{Separierbare Differentialgleichungen}
Gegeben
\[
\begin{cases}
	y' (x) & = f(x) \cdot g(y) \\
	y(x_0) &= y_0 
\end{cases}
\] 

in $D \subset \R ^2$. Falls $g(y) \neq 0$
lässt sich die DGL wie folgt aufteilen (und lösen):
\begin{align*}
	\frac{ y' }{ g(y) } &= f(x) \\
	\Rightarrow 
	\int_{y_0}^{y} \frac{ dz }{ g(z) } 
		&= 
		\int_{x_0}^{x} f(z) dz 
	\\
	\text{ Setze } H(y) 
		&= \int \frac{ dz }{ g(z) } 
		\text{ (Stammfunktion) } \\
		\Rightarrow H(y) 
		&= H(y_0)  + \int_{x_0}^{x} f(z) dz \\
		g(y) \neq 0 &\Rightarrow H(y)
		\text{ injektiv und invertierbar}
		\\
	\Rightarrow y(x)
	&= H ^{-1} \left(
		H(y_0) + \int_{x_0}^{x} f(z) dz
	\right)  
\end{align*}

\subsubsection{Ähnlichkeitsdifferentialgleichungen}
Ist eine DGL in Form:
\[
	y' (x) = f \left(
		\frac{ y }{ x }
	\right) 
\] 
können wir sie auf eine separierbare zurückführen:
\begin{align*}
	u(x) : &= \frac{ y(x) }{ x } \\
	\Rightarrow f(u) = y' (x)
	&= \left(
		x u(x)
	\right)' = u(x) + xu'(x) \\
	\Rightarrow u'(x) &= \frac{ f(u) - u }{ x }
	\; \text{ ist separierbar }
\end{align*}

\subsubsection{lineare Differentialgleichungen erster Ordnung}
\[
	y' (x) + a(x) y(x) = b(x)
\] 
\begin{itemize}
	\item $b(x)$ heisst \textbf{Inhomogenität} der Gleichung 
	\item DGL heisst \textbf{homogen} $\Leftrightarrow b(x) = 0$
	\item \textbf{allgemeine Lösung}:
		\begin{align*}
			& y(x) = y_p (x) + y_h (x) \text{ mit } \\
			& y_p(x) \text{ spezielle (partikuläre) Lösung der inhomogenen DGL } 
			\\
			& \text{und } y_h (x)
			\text{ allgemeine Lösung der homogenen Gleichung}\\
			& \qquad y_h '(x) + a(x) y_h (x) = 0
		\end{align*}
	\item Erinnerung: Diese DGL haben alle unendliche viele Lösungen,
		$y_p$ löst z.B. die gesamte Gleichung, $y_h + y_p$ ist aber die
		allgemeine Lösung. \underline{Alle} Lösungen dieser DGL
		sind in genau dieser Form.
\end{itemize}

\subsubsection*{1. Lösung der homogenen Gleichung}
\begin{align*}
	y_h '(x) + a(x) y_h (x) &= 0 \text{ ist separierbar } \\
	\Rightarrow \frac{ y_h ' }{ y_h } = -a(x) 
	&\Rightarrow
	\int \frac{ d y_h }{ y_h } = - \int a(z) dz
	\\
	\Rightarrow
	y_h (x) &= C \cdot \exp \left(
		- \int_{x_0}^{x} a(z) dz 
	\right) 
\end{align*}

mit $C \in \R$ beliebig.

\subsubsection*{2. Lösung der inhomogenen Gleichung}
\begin{align*}
	y_p (x) &= C(x) \cdot \exp \left(
		- \int_{x_0}^{x} a(z) dz 
	\right) \\
	\overset{\text{Einsetzen}} \Longrightarrow
	C' (x) \cdot \exp \left(
		- \int_{x_0}^{x} a(z) dz 
	\right) &- a(x) y_p (x) + a(x) y_p (x) = b(x) \\
	\Rightarrow C(x) &= 
	\int_{x_0}^{x} b(z) \cdot \exp \left(
		\int_{x_0}^{z} a (\gamma) d \gamma 
	\right) dz \\
	\Rightarrow y_p (x) &= 
	\left(
		\int_{x_0}^{x} b(z) \cdot \exp \left(
			\int_{x_0}^{z} a (\gamma) d \gamma 
		\right) dz
	\right) \cdot \exp \left(
		- \int_{x_0}^{x} a(z) dz 
	\right)
\end{align*}

Die allgemeine Lösung der DGL erhalten wir dann als Summe der beiden
Lösungen ($y_h(x) + y_p(x)$).

\subsubsection{Bernoullische Differentialgleichungen}
\[
	y' (x) + a(x) y(x) + b(x) (y(x)) ^{\alpha} = 0,
	\qquad \alpha \in \R \setminus \{
		0, 1
	\} 
\] 
Nach $u(x) := (y(x)) ^{1 - \alpha}$ zurückführen auf lineare
Differentialgleichung:
\[
	u'(x) + (1 - \alpha) a(x) u(x) = (1 - \alpha) b(x)
\] 

\textbf{Aufpassen} bei der Rücksubstitution:
\[
y = u ^{\frac{ 1 }{ 1- \alpha }}
\] 
kann z.B. bei $\alpha = 2$ singulär werden.

\subsubsection{Riccatische Differentialgleichungen}
\[
	y' (x) + a(x) y(x) + b(x) y ^2 (x) = c(x)
\] 
Bei gegebener spezieller Lösung $y_p (x)$, substituieren:
\[
	u(x) := \frac{ 1 }{ y(x) - y_p (x) }, \text{ also }
	y(x) = y_p (x) + \frac{ 1 }{ u(x) }
\] 
wir erhalten lineare DGL:
\[
	u' (x) - \left(
		a(x) + 2b (x) y_p (x)
	\right) u(x) = b(x)
\] 

\subsubsection{Exakte Differentialgleichungen}
\[
	g(x, y(x)) + h(x, y(x)) y' (x) = 0
\] 
Gibt es Funktion $\phi(x, y)$, sodass
\[
	\frac{ \partial \phi (x,y) }{ \partial x } = 
	g(x, y(x))
	\qquad
	\text{ und }
	\qquad
	\frac{ \partial \phi (x,y) }{ \partial y } = 
	h(x, y(x))
\] 
Dann ist die DGL $g + hy' = 0$ \textbf{exakt}.
Dann gilt:
\[
	\frac{ d \phi (x, y) }{ dx }
	= 
	\frac{ \partial \phi (x,y) }{ \partial x }
	+
	\frac{ \partial \phi (x,y) }{ \partial y } y' (x) = 0
\] 
Die Lösungen der Gleichung sind dann gegeben durch:
\[
	\phi (x, y) = C, \qquad
	\text{ für } C \in \R \text{ konstant }
\] 

\subsubsection{Einschub - Vektorfeld}
\begin{align*}
	F(x, y) := \left(
		g(x, y), h(x, y)
	\right) ^{T}
\end{align*}
$F$ heisst Vektorfeld. Die DGL heisst \textbf{exakt} falls $F$
ein Potential $\phi(x, y)$ besitzt.

\subsubsection{Lösung exakter Differentialgleichung}
\textbf{Existenz des Potentials $\phi (x,y)$ im Vektorfeld $F$} 
\\

Potential existiert $\Leftrightarrow$
Im Definitionsbereich gilt:
\[
	\frac{ \partial h }{ \partial x } (x, y) =
	\frac{ \partial g }{ \partial y } (x, y)
\] 

Dann kann das Potential wie folgt berechnet werden:
\[
	\phi (x, y) = \int_{C_{(x,y)}} F(\tau, \eta) d(\tau, \eta)
\] 
Wobei $C_{(x,y)}$ eine $C^{1}$-Kurve ist die $(x_0, y_0)$ (fest) mit
$(x, y)$ verbindet.
\\

TODO: Beispiel rechnen und besser erklären (die Berechnung eines solchen).

\subsection{Existenz und Eindeutigigkeit Lösungen gewöhnlicher DGL}

\subsubsection{Lipschitz-Bedingung}
$G\subset \R \times \R ^{n}$ und $f: G \rightarrow \R ^{n}$
gegebene Funktion.

\begin{enumerate}
	\item $f$ genügt in $G$ einer (globalen) \textbf{Lipschitz-Bedingung} 
		bezüglich $y$ mit Lipschitz-Konstante $L \geq 0$, wenn
		\[
			\forall (x, y), (x, \tilde{y}) \in G:
			\| f(x, y) - f(x, \tilde{y}) \| \leq L \| y - \tilde{y} \|
		\] 
	\item $f$ genügt in $G$ \textbf{lokal} einer Lipschitz-Bedingung bezüglich
		$y$, wenn
		\[
			\forall (a, b) \in G: \exists \; U \text{ Umgebung von } (a, b):
			f \text{ in } G \; \cap \; U 
			\text{ (global) Lipschitz-Bedingung genügt (bezüglich $y$) }
		\] 
\end{enumerate}

\subsubsection{Gleichheit von Lösungen von DGL}
\begin{gather*}
	G\subset \R \times \R ^{n}, \quad
	f: G \rightarrow \R ^{n} \text{ stetig }, \quad
	f \text{ genügt lokal Lipschitz-Bedingung bezüglich } y \\
	\text{ Im Intervall } I \subset \R
	\text{ sind zwei Lösungen } \varphi, \psi: I \rightarrow \R ^{n}
	\text{ der DGL } \\
	y' (x) = f(x, y(x)) \text{ mit }
	\varphi (x_0) = \psi (x_0) \text{ für } x_x \in I
	\text{ bekannt. } \\
	\\
	\Rightarrow \forall x \in I: \varphi (x) = \psi(x) 
\end{gather*}

\subsubsection{Existenz einer Lösung}
\begin{gather*}
	G\subset \R \times \R ^{n}, \quad
	f: G \rightarrow \R ^{n} \text{ stetig }, \quad
	f \text{ genügt lokal Lipschitz-Bedingung bezüglich } y \\
	\forall (x_0, y_0) \in G \; \exists \; \varepsilon > 0, \;
	\exists \; \varphi : [x_0 - \varepsilon, x_0 + \varepsilon] \rightarrow \R ^{n}
	\text{ Lösung von } \\
	\\
	y' (x) = f(x, y(x)), \quad y(x_0) = y_0
\end{gather*}

TOTO: hier genau herausfinden was dieser Satz definiert

\subsection{Lineare Systeme erster Ordnung}
\[
	y'(t) = A(t) y(t) +b(t), \qquad
	A(t) \in \R ^{n,n}, b(t) \in \R
	\text{ beide stetig }
\] 

\begin{itemize}
	\item Jede Lösung hat Form (wegen Linearität):
		\[
			y(t) = y_h (t) + y_p (t)
		\] 
	\item Lösungen $y_h ' = A y_h$ bilden reellen Vekorraum
		es genügt zum aufstellen der allgemeinen Lösung, das Ermitteln einer
		Basis des Lösungsraums. Die Basiselemente bilden zusammengefasst
		die Fundamentalmatrix.
\end{itemize}

Wir schauen uns jetzt die allgemeine Lösungsmethode solcher
Systeme an.

\subsubsection{Lösung homogene Gleichung}
\[
	y_h ' = A y_h
\]
Ermittle Basis für Lösungen von $y_h$.
\begin{gather*}
	(w_1(t), ..., w_{n} (t)) ^{T} \text{ Basis von } \R ^{n},
	\text{ Berechne $n$ Anfangswertaufgaben: } \\
	\text{ für } k \in \{
		1, ..., n
	\}: \;
	y_{k}' (t) = A(t) y_{k} (t) \text{ und }
	y_k (t_0) = w_k
\end{gather*}

Immer jeweils $k$-ten Eintrag der Vektoren betrachten.
Lösungen $y_k (t)$ bilden Fundamentalmatrix $Y(t)$:
\[
	Y(t) := (y_1 (t), y_2 (t), ..., y_n (t))
\] 
Nun erhalten wir allgemeine Lösung der \textbf{homogenen} DGL:
\[
	y_h (t) = Y(t) \cdot \begin{pmatrix} a_1 \\ \vdots \\ a_n \end{pmatrix},
	a \in \R ^{n}
\]

\subsubsection{Lösung inhomogene Gleichung}
Wie vorher, homogenen Ansatz durch Variation der Konstanten.
\[
	y_p (t) = Y(t) \cdot a(t)
\]
Unterschied hier, $a$ nicht mehr konstant, sonder hängt von $t$ ab.
\begin{gather*}
	Y(t) \cdot a' (t) = b(t)
	\Rightarrow a(t) = a(t_0) +
	\int_{t_0}^{t} Y ^{-1}  (s) b(s) \; ds \\
	y(t) = Y(t) \left(
		a(t_0) + 
		\int_{t_0}^{t} Y ^{-1}  (s) b(s) \; ds
	\right), \qquad
	y(t_0) = y_0
	\text{ (Anfangswert nicht Index von $y$) }
\end{gather*}
Ist allgemeine Lösung der DGL.

\subsubsection{Lösung im Fall zeitinvarianter Matrix}
\[
	y'(t) = A y(t), \qquad
	A \in \R ^{n,n} \text{ unabhängig von $t$}
\]
Ansatz:
\[
	y(t) = e ^{\lambda t} v, \quad
\] 
\textbf{Berechnung allgemeiner Lösung:} 

1. Eigenwerte von $A$ berechnen.

2. Für die Eigenwerte $\lambda_i$ welche wir erhalten folgende
Fälle 

\begin{enumerate}
	\item[(i)] Alle Eigenwerte sind reell,
		es existiert Basis aus Eigenvektoren. Allgemeine
		Lösung des Systems:
		\[
			y_h (t) = \sum_{k=1}^{n} a_k e ^{\lambda_k \cdot t}
			v_k, \qquad
			a_k \in \R
		\] 
	\item[(ii)] $A$ ist diagonalisierbar.
		es existiert Basis aus ggf. komplexen Eigenvektoren. Allgemeine
		Lösung des Systems:
		\[
			y_h (t) = \sum_{k=1}^{n} a_k e ^{\lambda_k \cdot t}
			v_k, \qquad
			a_k \in \mathbb{C}
		\] 
	\item[(iii)] $A$ ist nicht diagonalisierbar
		$\rightarrow$ Jordanische Normalform von $A$ berechnen.
		\begin{align*}
			B &= S ^{-1} A S =
			\begin{pmatrix} 
				J_1 & & 0 \\
					& \ddots & \\
				0 & & J_m
			\end{pmatrix}, \\
			J_i &= \text{Jordan-Kästchen}, \quad
			i \in \{
				1, ..., m
			\} \\
			S &:= \left(
				s_1 ^{(1)}, s_2 ^{(1)}, ...,
				s_{r_1} ^{(1)}, s_1 ^{(n)}, ...,
				s_1 ^{(m)}, ...,
				s_{r_m} ^{(m)}
			\right)  \\
			s_1 ^{(i)}  &:= \text{ Eigenvektor zum }
			r_i\text{-fachen Eigenwert } \lambda_i,\quad i \in \{
				1, ..., m
			\} 
			\\
			s_k ^{(i)} &:= (k-1)-\text{ter Hauptvektor zum}
			\text{ Eigenwert } \lambda_i,\quad i \in \{
				1, ..., m
			\} 
		\end{align*}
		\[
		\text{Es gilt: }
		\left(
			A - \lambda_i I_n
		\right) s_k ^{(i)} = s_{k-1} ^{(i)}, \qquad
		k \in \{
			2, ..., r_i
		\} 
		\] 
		\begin{enumerate}
			\item[1.] System transformieren auf $z(t) := S ^{-1} y(t)$
			\item[2.] Neues DGL-System zerfällt in Jordan-Blöcke
				z.B. erstes Jordan-Kästchen ergibt folgendes
				DGL:
				\[
				\frac{ d }{ dt } 
				\begin{pmatrix} 
					z_1 \\
					z_2 \\
					\vdots \\
					z_{r_1}
				\end{pmatrix} 
				=
				\begin{pmatrix} 
					\lambda_1 & 1 & & 0 \\
					  & \lambda_1 & \ddots & \\
					& & \ddots & 1 \\
					0 & & & \lambda_1 \\
				\end{pmatrix} 
				\begin{pmatrix} 
					z_1 \\
					z_2 \\
					\vdots \\
					z_{r_1}
				\end{pmatrix} 
				\]
				Hier erhalten wir ein Differentialgleichungssystemen, welches
				wir wie folgt lösen können:
				\setcounter{equation}{0}
				\begin{gather}
					z_{r_1}' = \lambda_1 z_{r_1}
					\text{ (letzte Gleichung) }
					\Rightarrow z_{r_1}
					= c_{1} \cdot e ^{\lambda_1 t},
					c_{1} \in \R \text{ konstant }
					\\
					\Rightarrow 
					z_{r_1 - 1}' = \lambda_1 z_{r_1 - 1}
					+ c_{1} \cdot r ^{\lambda_1 t}
					\Rightarrow z_{r_1 - 1} = 
					e ^{\lambda_1 t} \left(
						\tilde{c_2} t + c_2
					\right) \\
					\Rightarrow
					\cdots \Rightarrow
					z_{r_1 -2} = e ^{\lambda_1 t} \left(
						\tilde{c_3} \cdot \frac{ 1 }{ 2 } t^2
						+ c_3
					\right)  \text{ setze Konstanten } =1 \\
					\Rightarrow z(t) =
					e ^{\lambda_1 t} \begin{pmatrix} 
						\frac{ t ^{r-1} }{ (r-1)! } \\[1em]
						\frac{ t ^{r-2} }{ (r-2)! } \\[1em]
						\vdots \\[1em]
						\frac{ t ^2 }{ 2! } \\[1em]
						\frac{ t }{ 1! } \\[1em]
						1 
					\end{pmatrix} 
					= e ^{\lambda_1 t}
					\cdot s_k ^{(1)}
				\end{gather}
				Nun haben wir den letzten Hauptvektor gefunden. Um die anderen
				Hauptvektoren zu finden setzen wir bei Gleichung (1)
				statt $z_{r_1} = c_1 \cdot e ^{\lambda_1 t}$,
				$z_{r_1} = 0$ welches ebenfalls die Differentialgleichung
				$z_{r_1}' = \lambda_1 z_{r_1}$ löst.
				Dann wird Gleichung (2) genau zur vorigen Gleichung (1), also
				$z_{r_1 - 1}' = z_{r_1 - 1} + 0 (= z_{r_1})$
				Und wir erhalten den selben Lösungsvektor welcher nur um
				eins nach oben verschoben wurde. Alle Hauptvektoren
				dieses Jordan-Kästchen sehen dann wie folgt aus:
				\[
				e ^{\lambda_1 t}
				\begin{pmatrix} 
					1 \\
					0 \\
					\vdots \\
					\vdots \\
					\vdots \\
					0
				\end{pmatrix},
				e ^{\lambda_1 t}
				\begin{pmatrix} 
					t / 1! \\
					1 \\
					0 \\
					\vdots \\
					\vdots \\
					0
				\end{pmatrix},
				e ^{\lambda_1 t}
				\begin{pmatrix} 
					t ^2 / 2! \\
					t / 1! \\
					1 \\
					0 \\
					\vdots \\
					0
				\end{pmatrix},
				... ,
				e ^{\lambda_1 t}
				\begin{pmatrix} 
					\frac{ t ^{r-1} }{ (r-1)! } \\
					\vdots \\
					\vdots \\
					\vdots \\
					t / 1! \\
					1
				\end{pmatrix}
				\] 
				Wichtig ist, das sind nur die Hauptvektoren zu dem ersten
				Jordan-Kästchen. Um die gesamte Transformationsmatrix $S$
				zu ermitteln müssen wir alle Hauptvektoren finden.
				Wir erhalten folgende Lösungen nach Rücktransformation:
				\begin{align*}
					y^{(1, 1)} (t)
					&= e ^{\lambda_1 t} s_1 \\
					y^{(1, 2)} (t)
					&= e ^{\lambda_1 t} \left(
						\frac{ t }{ 1! } s_1 + s_2
					\right)  \\
					& \vdots \\
					y^{(1, r_1)} (t)
					&= e ^{\lambda_1 t} \left(
						\frac{ t ^{r_1 - 1} }{ (r_1 - 1) ! } s_1 +
						\cdots +
						\frac{ t }{ 1! } s_1 + s_2
					\right) 
				\end{align*}
				Sind die Lösungen zum Eigenwert $\lambda_1$, andere
				Lösungen sind mit $y ^{(i, k)}$ gekennzeichnet.
				(Für den $i$-ten Eigenwert)
		\end{enumerate}
\end{enumerate}

\subsection{Stabilität(sbegriffe) von Differentialgleichungs-Systemen}
\[
	y' (t) = f (t, y(t)), \qquad
	y(t) \in \R ^{n}
\] 
$y^{*} (t)$ sei spezielle Lösung der DGL.
Untersuche wie sich benachbarte Lösungen $y(t; t_0, y_0)$
verhalten.
\\

Begriffe von Stabilität in Differentialgleichungssystemen:

\begin{itemize}
	\item Lösung $y^{*} (t)$ heisst \textbf{stabil} auf $I \subset \R$,
		falls $\forall t_0 \in I, \varepsilon > 0: \;
		\exists \delta > 0: \forall y_0 \text{ mit }
		\| y_0 - y^{*} (t) \| < \delta$ gilt:
		\[
			\forall t \in I: \qquad
			\| y(t; t_0, y_0) - y^{*} (t) \| < \varepsilon
		\] 
	\item ist $\delta$ unabhängig von $t_0$ $\Rightarrow$
		$y^{*} (t)$ ist \textbf{gleichmässig stabil} auf $I$.
	\item Falls $y ^{*} (t)$ auf $[a, \infty)$ definiert ist, dann heisst
		$y^{*} (t)$ \textbf{asymptotisch stabil}, falls $y ^{*} (t)$
		dort stabil ist und $\forall t_0 \geq a:\; \exists \delta > 0$,
		sodass:
		\[
		\forall y_0 \text{ mit } \| y_0 - y^{*} (t) \| < \delta :
		\lim_{t \to \infty} \| y(t; t_0, y_0) - y^{*} (t) \| = 0
		\] 
	\item $y ^{*} (t)$ ist gleichmässig und asymptotisch stabil
		$\Rightarrow$ $y ^{*} (t)$ heisst \textbf{strikt stabil} 
\end{itemize}

\begin{itemize}
	\item Es reicht aus die Stabilität der Nulllösung zu prüfen.
\end{itemize}

\subsubsection{Stabilitätssatz 1 bei linearen DGL}
\[
	y' (t) = A(t) y(t), \qquad
	\text{ mit } a \leq t < \infty
	\; (a \text{ konstant) }
\] 
$A(t)$ stetige Matrix und $Y(t)$ bel. Fundamentalsystem.

\begin{enumerate}
	\item Nulllösung $y ^{*} (t) = 0$ ist stabil auf $I=[a, \infty)$
		$\Leftrightarrow$ $Y(t)$ ist auf $I$ beschränkt.
		
		$\Leftrightarrow$ Finde ich eine konstante Matrix $B \in \R ^{n,n}$,
		sodass $\forall t \in I: Y(t) \leq B$?

		Insbesondere auch bei $t \to \infty$.
	\item Nulllösung $y ^{*} (t)$ ist gleichmässig stabil auf $I$
		\[
		\Leftrightarrow \exists M > 0: \forall t \geq t_0 \geq a:
		\| Y(t) Y (t_0) ^{-1} \| \leq M
		\] 
	\item Nulllösung $y ^{*} (t)$ ist asymptotisch stabil
		\[
		\Leftrightarrow \lim_{t \to \infty} 
		\| Y(t) \| = 0
		\]
	\item Weiteres Stabilitätskriterium (Eigenwert)
		\\

		$\lambda (t)$ sei grösster Eigenwert von $A(t) + A(t) ^{T}$:
		\[
			\int_{t_0}^{\infty} \lambda (t) dt = - \infty 
			\Rightarrow \forall y(t) \text{ Lösung von }
			y' = A(t) y :
			\lim_{t \to \infty} y(t) = 0
		\] 
		Und dann ist die Nulllösung $y ^{*} (t) = 0$
		asymptotisch.
\end{enumerate}

\subsubsection{Stabilitätssatz 2 bei linearen DGL}
Gleiches DGL (wie beim vorigen Satz), konstante Matrix $A \in \R ^{n,n}$.
\\

Die Nulllösung $y ^{*} (t)$ ist genau dann
\begin{enumerate}
	\item \textbf{strikt stabil} $\Leftrightarrow$
		$\forall \lambda_j $ Eigenwert von $A: Re(\lambda_j) < 0$.
	\item \textbf{gleichmässig stabil} $\Leftrightarrow$
		\[
			\forall \lambda_j
			\text{ Eigenwert von }A : \;
			Re (\lambda_j)
			\text{ und }
			Re (\lambda_j) = 0
			\Rightarrow g( \lambda_j ) = a( \lambda_j )
		\] 
		(geometrischen Vielfachheiten und arithmetischen Vielfachheiten
		stimmen überein)
	\item In allen anderen Fällen ist die Nulllösung 
		$y ^{*} (t)$ \textbf{instabil}.
\end{enumerate}

\subsubsection{Stabilitätsuntersuchung durch Linearisierung bei nichtlinearen Gleichungen}
Stabilitätsuntersuchung nichtlinearer autonomer Systeme:
\[
	y' (t) = f(y(t)), \qquad 
	f(0) = 0, y ^{*} = 0
	\text{ ist GGP }
\] 

Wir linearisieren die rechte Seite und versuchen dann Kriterien für
lineare Systeme anzuwenden.
\begin{align*}
	y' (t) &= A y(t) + g(y(t)) \\
	A &= J_f (0) \\
	g(y) &= o( \| y \| ), 
	\text{ mit } g(0) = 0
\end{align*}
$o( \| y \| )$ ist Landau-Symbole.
Es folgt nach Taylor-Entwicklung um $y^* = 0$:
\[
	f(y) = f( 0 ) + J_f (0) y + g(y)
\] 

\subsubsection{Stabilitätssatz 3 für nichtlineare Gleichungen}
Falls gilt:
\begin{gather*}
	\forall \lambda_j \text{ Eigenwerte von } A = J_f (0):
	Re (\lambda_j) \leq 0
	\text{ und } \\
	\exists \lambda_j \text{ Eigenwert von } A:
	Re (\lambda_j) = 0
\end{gather*}
dann können wir folgenden Stabilitätssatz \textbf{nicht} anwenden.
Bei $Re(\lambda_j) = 0$ sind die geom. bzw. algebraischen Vielfachheiten
hier egal.
\\

Andernfalls gilt nach dem linearisieren:

\begin{enumerate}
	\item 
		\[
			\forall \lambda_j \text{ Eigenwerte von }
			A = J_f (0): Re (\lambda_j) < 0
		\] 
		$\Rightarrow$ $y ^{*} = 0$ ist \textbf{strikt stabiler} 
		Gleichgewichtspunkt von $y' = f(y)$, also ist das nichtlineare
		System auch stabil.
	\item Gibt es einen Eigenwert $\lambda_j$ von $J_f (0)$ mit:
		\[
		Re (\lambda_j) > 0
		\] 
		$\Rightarrow$ Dann ist $y ^{*} = 0$ \textbf{instabil}.
\end{enumerate}

\subsubsection{Stabilitätssatz 4 bei nichtlinearen DGL - Ljapunov Methode}
\subsubsection*{Definition - Ljapunov-Funktion}
Eine $C^{1}$-Funktion $V: D \to \R, D \subset \R$ heisst Ljapunov-Funktion

\end{document}
