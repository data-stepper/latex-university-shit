\documentclass[a4paper]{article}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
\usepackage[german]{babel}

\usepackage{tikz}
\usetikzlibrary{automata, positioning}

\pdfminorversion=7
\pdfsuppresswarningpagegroup=1

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\beh}{\textit{Behauptung. }}

\setlength{\parindent}{0pt}

\begin{document}

\begin{titlepage}
	\begin{center}
		\vspace*{1cm}

		\textbf{Mathematische Modellierung}

		\vspace{0.5cm}
		\section*{
			Notizen für die Klausur
		}

		\vspace{1.5cm}

		\textbf{Bent Müller (7302332)}

		\vfill

		\vspace{0.8cm}


		Fachbereich Mathematik\\
		Universität Hamburg\\
		Deutschland\\
		20.08.2021

	\end{center}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak

\section{Funktionsapproximation}

\subsection{Rationale Interpolation}

Funktioniert ähnlich wie normale Interpolation, mit dem entscheidenden
Unterschied, dass wir hier einen \textbf{Bruch} von Polynomen benutzen.

\[
	R_{m, n} (x) := \frac{ 
		P_m (x)
	}{ Q_n (x) } \text{ mit }
	P_m (x) := \sum_{k=0}^{m} a_k x^{k}, \;
	Q_n (x) := \sum_{k=0}^{n} b_k x^{k}, \;
\] 

\begin{itemize}
	\item Polynomgrade $m$ und $n$ sind gegeben
	\item Es soll gelten für bekannte $x_i$: ($f$ ist die zu 
		interpolierende Funktion)
		\[
			f(x_0) = R_{m, n} (x_0), ...,
			f(x_1) = R_{m, n} (x_1)
		\] 
	\item $m+n+2$ freie Koeffizienten
	\item Oft wird normiert durch $b_0 = 1$
	\item $m+n \; (=s)$ = Anzahl Freiheitsgrade (= Anzahl Interpolationsbedingungen)
	\item Wir erhalten lineares homogenes Gleichungssystem:
		\[
			P_m (x_i) - f(x_i) Q_n(x_i) = 0
			\qquad i \in \{
				0, ..., m+n
			\} 
		\] 
	\item Dieses LGS hat immer eine nicht-triviale Lösung.
	\item Es kann passieren, dass es unerreichbare Punkte gibt, für solche
		braucht man mehr Freiheitsgrade.
\end{itemize}

\subsection{Ausgleichsrechnung mit rationalen Funktionen}

Hier schauen wir uns Kriterien für die Bestimmung der Koeffizienten an.
Geläufig ist das Gaußsche Prinzip der kleinsten 
\textbf{Summe der Fehlerquadrate}.
\\

Problem ist nämlich, dass man oft mehr Beobachtungen zur Interpolation
hat als man der rationalen Funktion Freiheitsgrade geben möchte.
\\

Zur Notation:
\begin{itemize}
	\item $b_0 = 1$ (normiert)
	\item $(x_0, f_0), \; ... \;, (x_s, f_s)$
		ist die Folge an Beobachtungen
	\item $m + n + 1 < s =$ Anzahl an Beobachtungen
\end{itemize}

\subsubsection{Kleinste Summe von Fehlerquadraten}

\[
\rho \left(
	a_0, a_1, ..., a_m,
	b_1, b_2, ..., b_n
\right) :=
\sum_{i=0}^{s} \left[
	P_m (x_i) - f(x_i) Q_n (x_i)
\right] ^2
\] 

\begin{itemize}
	\item Im Fall $m+n+1 = s$ finden wir die eindeutige Lösung 
		(das LGS von vorher).
	\item Ansonsten: Minimum der oberen Gleichung finden.
\end{itemize}

Hierfür müssen wir den Gradienten der Fehlerquadrate gleich $0$ setzen.
\begin{align*}
	& \nabla
		\rho \left(
			a_0, a_1, ..., a_m,
			b_1, b_2, ..., b_n
		\right) 
		\text{ (Gradient) }
		\\
	&= \left(
		\frac{ \partial \rho }{ \partial a_0 },
		\frac{ \partial \rho }{ \partial a_1 },
		...,
		\frac{ \partial \rho }{ \partial a_m },
		\frac{ \partial \rho }{ \partial b_1 },
		\frac{ \partial \rho }{ \partial b_1 },
	\right) 
\end{align*}

Wir können diese Gleichung dann weiter auflösen und erhalten am Ende durch
umsortieren ein LGS, welches wie folgt aussieht.

\begin{align*}
	& \begin{pmatrix} 
		s+1 &
		\sum_{i} x_i &
		\cdots &
		\sum_{i} x_i ^{m} &
		- \sum_{i} f_i x_i &
		\cdots &
		- \sum_{i} f_i x_i ^{n} \\[1em]
		\sum_{i} x_i &
		\sum_{i} x_i ^2 &
		\cdots &
		\sum_{i} x_i ^{m+1} &
		- \sum_{i} f_i x_i ^2 &
		\cdots &
		- \sum_{i} f_i x_i ^{n+1} \\[1em]
		\vdots &
		\vdots &
		\ddots &
		\vdots &
		\vdots &
		\ddots &
		\vdots \\[1em]
		\sum_{i} x_i ^{m} &
		\sum_{i} x_i ^{m+1} &
		\cdots &
		\sum_{i} x_i ^{2m} &
		- \sum_{i} f_i x_i ^{m+1} &
		\cdots &
		- \sum_{i} f_i x_i ^{m+n} \\[1em]
		\sum_{i} f_i x_i &
		\sum_{i} f_i x_i ^2 &
		\cdots &
		\sum_{i} f_i x_i ^{m+1} &
		- \sum_{i} f_i ^2 x_i ^2 &
		\cdots &
		- \sum_{i} f_i ^2 x_i ^{n+1} \\[1em]
		\sum_{i} f_i x_i ^2 &
		\sum_{i} f_i x_i ^3 &
		\cdots &
		\sum_{i} f_i x_i ^{m+2} &
		- \sum_{i} f_i ^2 x_i ^3 &
		\cdots &
		- \sum_{i} f_i ^2 x_i ^{n+2} \\[1em]
		\vdots &
		\vdots &
		\ddots &
		\vdots &
		\vdots &
		\ddots &
		\vdots \\[1em]
		\sum_{i} f_i x_i ^n &
		\sum_{i} f_i x_i ^{n+1} &
		\cdots &
		\sum_{i} f_i x_i ^{m+n} &
		- \sum_{i} f_i ^2 x_i ^{n+1} &
		\cdots &
		- \sum_{i} f_i ^2 x_i ^{2n} \\[1em]
	\end{pmatrix} 
	\begin{pmatrix} 
		a_0 \\[1em]
		a_1 \\[1em]
		\vdots \\[1em]
		a_m \\[1em]
		b_1 \\[1em]
		b_2 \\[1em]
		\vdots \\[1em]
		b_n \\[1em]
	\end{pmatrix} \\
	&= \left(
		\sum_i f_i, \;
		\sum_i f_i x_{i}, \;
		\cdots, \;
		\sum_i f_i x_{i} ^{m}, \;
		\sum_i f_i ^2 x_{i}, \;
		\cdots, \;
		\sum_i f_i ^2 x_{i} ^{n}, \;
	\right) ^{T}
\end{align*}

\subsection{Pad\'e Approximation}

Idee: Bestimme rationale Funktion, sodass die Potenzreihen-Entwicklung (PRE)
soweit wie möglich mit der PRE von der zu approximierenden Funktion übereinstimmt.
\\

Oft wird hier als PRE die Taylorreihe benutzt.

\subsubsection{Taylorreihen-Entwicklung}

\[
	T_{n} ( f(x; a) ) = 
	\sum_{k=0}^{n} \frac{ f ^{(k)} (a) }{ k! } (x - a) ^{k}
	\quad \text{ mit }
\] 
\[
	f ^{(k)},
	\text{ $k$-te Ableitung von $f$; } \quad
	a,
	\text{ Entwicklungspunkt }
\] 

\subsubsection{Pad\'e Approximation - Definition}

\begin{align*}
	& R_{m, n} (x) \text{ ist Pad\'e Approximierende } \\
	& \Leftrightarrow \forall k \in \{
		0, 1, ..., m+n
	\} : 
	\frac{ d ^{k} }{ d x ^{k} } R_{m, n} (0)
	=
	\frac{ d ^{k} }{ d x ^{k} } f (0) \\
	& \Leftrightarrow \text{ jeweils $k$-ten Ableitungen stimmen überein }
\end{align*}

Wir erhalten daraus folgende Gleichungen:
\begin{align*}
	& \sum_{j=0}^{k} b_j c_{k-j} = a_k
	\text{ für } k \in \{
		0, ..., m
	\} \text{ und } \\
	& \sum_{j=0}^{k} b_j c_{m-j+k} = 0
	\text{ für } k \in \{
		1, ..., n
	\}  \\
	& \text{ und wieder } b_0 = 1
\end{align*}

\subsubsection{Quotientenregel - Ableitung}

\[
	\left(
		\frac{ f(x) }{ g(x) }
	\right) '
	=
	\frac{ f' (x) g(x) - f(x) g' (x) }{ g ^2 (x) }
\] 

\section{Optimierung}

\subsection{Geometrische Lösung linearer Optimierung im $\R ^2$}

==\gg In Progress
\\

Einfache Skizze / Anleitung zur Lösung solche aufgaben muss hier angefertigt
werden.

\subsection{lineare Optimierung im $\R ^{n}$}

\begin{itemize}
	\item Bei $\max$-Optimierungsaufgaben die Zielfunktion mit $-1$
		multiplizieren und Minimum berechnen.
\end{itemize}

\subsubsection{Beispiel Schuhfabrik}

Jeden Monat stehen zur Verfügung:

\begin{itemize}
	\item $8000$ Stunden Herstellungszeit
	\item $2000$ Stunden Maschinenzeit
	\item $4500\; dm ^2$ Leder
\end{itemize}

Pro Schuh $16$ Euro für Damenschuh und $32$ Euro für Herrenschuh.
\\

Stelle Nebenbedingung auf:

\begin{align*}
	20 x_1 + 10 x_2 & \leq 8000 \\
	4 x_1 + 5 x_2 & \leq 2000 \\
	6 x_1 + 15 x_2 & \leq 4500 \\
	x_1 & \geq 0 \\
	x_2 & \geq 0 & \\
\end{align*}

Maximiere Zielfunktion $Z(x_1, x_2) = 16 x_1 + 32 x_2 \rightarrow \max !$.

\section{Dynamische Systeme (Prozesse)}

Beschreibung der Zeit $t$ und aller möglichen Zustände, einem sog.
Zustandsraum $X$.

\subsection{Deterministische zeitdiskrete dynamische Systeme}

Modell:

\[
	x(t+1) = F(x(t)) \text{ oder } x(t+1) = x(t) + f(x(t))
	\text{ mit } t \in \N_0
\] 

\subsubsection{Fixpunkte}

\begin{align*}
	& x ^{*} \in X \text{ ist Fixpunkt } \\
	& \Leftrightarrow x ^{*} = F ( x ^{*} ) \\
	& \Leftrightarrow x ^{*} \text{ bleibt auf sich sitzen }
\end{align*}

\subsubsection{Differenzengleichungen}


\begin{align*}
	& f(t, x(t), x(t+1), ..., x(t+k)) = 0 \qquad
	\forall t \in \mathbb{N} \\
	& \text{ mit } f: \N \times D^{k+1} \rightarrow \mathbb{K}
	\text{ und } D \subseteq \mathbb{K}
\end{align*}

\begin{itemize}
	\item $f$ gegeben und $x$ gesucht
	\item \textbf{autonom} $\Leftrightarrow$ 
		$f$ hängt nicht explizit von $t$ ab.
	\item $k$ ist \textbf{Ordnung} oder \textbf{Grad} 
	\item $x: \N \rightarrow D$ heißt \textbf{Lösung}
\end{itemize}

\subsection{Dynamische stochastische Prozesse}

\subsection{Dimensionsanalyse und Skalierung}

\subsection{Gewöhnliche Differentialgleichungen}

\end{document}
