\documentclass[10pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
 \usepackage{bbm, mathtools}
 
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\B}{\mathbb{B}}
\newcommand{\gap}{\,\vert\,}
\newcommand{\beh}{\textit{Behauptung. }}

\setlength{\parindent}{0pt}
 
\newenvironment{Aufgabe}[2][Aufgabe]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{amatrix}[1]{%
  \left(\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right)
}

\begin{document}
 
\title{ \textbf{Maßtheoretische Konzepte der Stochastik \\ -- Übungsblatt \#08 --} }

\author{Amir Miri Lavasani (7310114), Bent Müller (7302332),
        Michael Hermann (6981007)}
\maketitle

\begin{Aufgabe}{1} % #1
\end{Aufgabe}

\beh

\begin{proof}[Beweis]
\end{proof}

\begin{Aufgabe}{2} % #2
	Es seien $(\Omega, \mathcal{A})$ und $(S, \mathcal{D})$ Maßräume und $Y:(\Omega, \mathcal{A}) \rightarrow (S, \mathcal{D})$ und $Z:(\Omega, \sigma(Y)) \rightarrow (\mathbb{R}, \mathbb{B})$ jeweils messbare Abbildungen. 
\end{Aufgabe}

\beh Es existiert eine Abbildung $h:(S, \mathcal{D}) \rightarrow  (\mathbb{R}, \mathbb{B})$, so dass $Z = h \circ Y$.

\begin{proof}[Beweis]
	Es sei $Y$ eine beliebige, aber fest gewählte Abbildung von der gewünschten Form. Wir zeigen die Aussage für alle Abbildungen $Z:(\Omega, \sigma(Y)) \rightarrow (\mathbb{R}, \mathbb{B})$ mit Hilfe von algebraischer Induktion. \\

	Sei zuerst $Z$ eine Elementarfunktion, dh. $Z = \sum_{i=1}^n a_i \mathbbm{1}_{A_i}$ für paarweise disjunkten Mengen $A_i \in \sigma(Y)$ und $0 < a_i \in \bar{\mathbb{R}}$ für $1 \leq i \leq n$. 
	Da die Mengen $A_i$ alle in $\sigma(Y)$ liegen, ist jede Menge $A_i$ das Urbild $Y^{-1}(B_i)$ einer Menge $B_i \in \mathcal{D}$. Für $\omega \in \Omega$ gilt dann $\mathbbm{1}_{A_i}(\omega) = \mathbbm{1}_{B_i}(Y(\omega)) = \mathbbm{1}_{B_i} \circ Y (\omega)$
	für alle $1 \leq i \leq n$ und es folgt $Z = h \circ Y$ für $h \coloneqq \sum_{i=1}^n a_i \mathbbm{1}_{B_i}$. Die so definierte Funktion ist natürlich auch messbar. \\

	Ist $Z$ eine beliebige nicht-negative Funktion $(\Omega, \sigma(Y)) \rightarrow (\mathbb{R}, \mathbb{B})$, dann gibt es eine Folge von Elementarfunktionen $(Z_k)_{k \in \mathbb{N}}$  mit $Z_k \uparrow Z$. Wie wir soeben gesehen haben, gibt es zu jedem $Z_k$ eine 	messbare Funktion $h_k$ mit $Z_k = h_k \circ Y$ und damit $h_k \circ Y \uparrow Z$ für $k \to \infty$. Aus der Monotonie der Konvergenz folgt die Existenz und Messbarkeit einer Funktion $h \coloneqq \lim_{k \to \infty} h_k$ und für diese gilt $Z = h \circ Y$. \\

	Ist schliesslich $Z$ eine beliebige messbare Funktion $(\Omega, \sigma(Y)) \rightarrow (\mathbb{R}, \mathbb{B})$, dann zerlegen wir sie in Positiv- und Negativteil, dh. $Z = Z^+ - Z^-$, und erhalten aus dem vorigen Schritt zwei Funktionen $h^+$ und $h^-$ mit den
	gewünschten Eigenschaften. Für $h \coloneqq h^+ - h^-$ gilt dann $h \circ Y = h^+\circ Y - h^-\circ Y = Z^+ - Z^- = Z$.  
\end{proof}

\begin{Aufgabe}{3} % #3
	Seien $X : (\Omega, \A, P)\to (\R, \B)$ und $Z_i : (\Omega, \A)\to (S_i, \D_i), i = 1,2$. Seien außerdem $X$ und $Z_2$
	bedingt stochastisch unabhängig gegeben $Z_1$.
\end{Aufgabe}

\beh Für alle Funktionen $h: (\R,\B)\to (\R,\B)$ mit $E[\,\vert h(X) \vert\,] < \infty$ und alle Mengen $D_2\in\D$ gilt 
	\begin{align*}
		E[h(X)1_{D_2}(Z_2) \,\vert\, Z_1] = E[h(X) \,\vert\, Z_1] \cdot E[1_{D_2}(Z_2) \gap Z_1] \quad\text{$P-$f.s.}
	\end{align*}

\begin{proof}[Beweis]
	Sei $B\in\A$. Da $X$ und $Z_2$ bedingt unabhängig gegeben $Z_1$ sind, sind es auch $1_B(X)$ und $1_{D_2}(Z_2)$. Also gilt 
	\begin{align*}
		E[1_B(X)1_{D_2}(Z_2) \gap Z_1] = E[1_B(X) \gap Z_1]\cdot E[1_{D_2}(Z_2) \gap Z_1].
	\end{align*}

	Sei nun $X_n := \sum_{i=1}^{n} c_i\cdot 1_{B_i}$ für $B_i\in\A,\, c_i\in\R_{>0},\, n\in\N$. Dann ist $X_n$ eine einfache Funktion. 
	Aus der Linearität des bedingten Erwartungswertes, folgt:
	\begin{align*}
		E[X_n(X)1_{D_2}(Z_2) \gap Z_1] &= \sum_{i=1}^{n} c_i E[1_{B_i}(X) 1_{D_2}(Z_2) \gap Z_1]		\\
									   &= \sum_{i=1}^{n} c_i E[1_{B_i}(X) \gap Z_1] \cdot E[1_{D_2}(Z_2) \gap Z_1] 
									   = E[X_n(X) \gap Z_1] \cdot E[1_{D_2}(Z_2) \gap Z_1].
	\end{align*}

	Die Behauptung gilt also für einfache Funktionen. Sei nun $h \geq 0$. Wähle $X_n$, so dass $X_n \uparrow h$ $P-$f.s. 
	Daraus folgt, dass auch $X_n 1_{D_2} \uparrow h 1_{D_2}$ $P-$f.s. Mit $5.3$ (vii) gilt dann ($P-$f.s.)
	\begin{align*}
		E[h(X) 1_{D_2}(Z_2) \gap Z_1] &= \lim_{n\to\infty} E[X_n(X) 1_{D_2}(Z_2) \gap Z_1]  \\
									  &= \lim_{n\to\infty} E[X_n(X) \gap Z_1]\cdot E[1_{D_2}(Z_2) \gap Z_1]  
									  = E[h(X) \gap Z_1]\cdot E[1_{D_2}(Z_2) \gap Z_1]. 
	\end{align*}

	Schließlich sei $h$ eine beliebige Funktion. Setze $h = h^+ - h^-$ mit $h^+, h^- \geq 0$. Dann folgt zusammen mit 
	der Linearität des bedingten Erwartungswertes und den vorherigen Ergebnissen ($P-$f.s.)
	\begin{align*}
		E[h(X) 1_{D_2}(Z_2) \gap Z_1] &= E[h^+(X) 1_{D_2}(Z_2) \gap Z_1] - E[h(X)^- 1_{D_2}(Z_2) \gap Z_1] 								    \\
									  &= E[h^+(X) \gap Z_1]\cdot E[1_{D_2}(Z_2) \gap Z_1] - E[h^-(X) \gap Z_1]\cdot E[1_{D_2}(Z_2) \gap Z_1] \\
									  &= E[h(X) \gap Z_1]\cdot E[1_{D_2}(Z_2) \gap Z_1].
	\end{align*}
\end{proof}

\end{document}












