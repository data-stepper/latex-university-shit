\documentclass[a4paper]{article}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
\usepackage[german]{babel}

\usepackage{tikz}
\usetikzlibrary{automata, positioning}

\pdfminorversion=7
\pdfsuppresswarningpagegroup=1

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\beh}{\textit{Behauptung. }}

\setlength{\parindent}{0pt}

\begin{document}

\begin{titlepage}
   \begin{center}
       \vspace*{1cm}

       \textbf{Ausarbeitung Proseminar}

       \vspace{0.5cm}
	   \section*{
		   Langzeitverhalten von Markowketten
	   }
            
       \vspace{1.5cm}

	   \textbf{Nogarbek Sharykpayev (6870965),\\ Bent Müller (7302332)}

       \vfill
            
       \vspace{0.8cm}
     
            
       Fachbereich Mathematik\\
       Universität Hamburg\\
       Deutschland\\
       17.08.2021
            
   \end{center}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak

\section{Kleine Wiederholung - Markowketten}

Bevor wir uns mit dem Langzeitverhalten der Markow-Ketten beschäftigen, folgt hier eine kleine Wiederholung:
\\

Der aktuelle Zustand einer Markow-Kette besitzt die Eigenschaft von Zuständen aus mindestens 2 Schritten aus der Vergangenheit unabhängig zu sein, also wenn gilt:

\subsection{Markowsche Eigenschaft}

1. Es sei $\{X_n : n \in \mathbb{Z} \}$ ein stochastischer Prozess mit dem abzählbaren Zustandsraum $I$ und es gilt für alle $i_0, …, i_{n+1}$ Element in $I$ : 

\[
	P(X_0 = i_0, ..., X_{n} = i_{n}) > 0 \\
\] 

\[
	P(X_{n+1} = i_{n+1} \; \vert \; X_0 = i_0, ..., X_{n} = i_{n})
	= 
	P(X_{n+1} = i_{n+1} \; \vert \; X_{n} = i_{n})

\] 


dann besitzt dieser stochastische Prozess die markowsche Eigenschaft und ist somit eine Markow-Kette

\subsection{Stationäre Übergangswahrscheinlichkeiten und stochastische Matrix}

2. Eine homogene Markov-Kette besitzt stationäre Übergangswahrscheinlichkeiten. Das bedeutet:

\[
	\forall i, j \in I: P(X_{n+1} = j \; \vert \; X_n = i) =: p_{ij}
\] 
Der Prozess ist damit unabhängig von $n$.
\\

Mit der letzten Eigenschaft lassen sich solche stochastischen Prozesse mittels folgender Gleichung
modellieren:

\[
	\mathbb{P} ^{n} x_0 = x_n
\] 

$\mathbb{P}$ : stochastische Matrix, die einen Markow-Prozess genau nach einem Schritt/Übergang beschreibt.

\begin{align*}
	\mathbb{P} = \left(
		p_{ij}
	\right) \text{ ist stochastische Matrix } & \Leftrightarrow \\
	p_{ij} \geq 0 \left(
		i, j \in I
	\right) \text{ und }
	\sum_{j \in I} p_{ij} = 1
\end{align*}

$x_0$ : Die Startverteilung (z.B. (1, 0,…,0) , der Prozess startet in dem ersten Zustand ) \\
$n$ : Anzahl der Schritte/Übergänge ( Zeitdiskretes Modell) \\
$x_n$ : Die Verteilung nach n-Übergängen (kein deterministischer Faktor mehr). \\

Nun zu der Leitfrage dieses Kapitels: Welche qualitativen Eigenschaften der Markow-Ketten haben
Einfluss auf das Langzeitverhalten des Prozesses. Die obere explizite Darstellung der Folge
$(X_n)_{n\in \mathbb{N}}$ zeigt die Wichtigkeit der Analyse der stochastischen Matrix. Was muss also für diese
Matrix P gelten, damit sie für $n \rightarrow \infty$ konvergiert ? Dies beantwortet der folgende Satz:

\section{Langzeitverhalten}

\subsection{Satz 1 - Konvergenz der Übergangsmatrix}

Unter der Voraussetzung, dass die L-Schritt-Übergangsmatrix 
$\mathbb{P} ^{L} = \left(
	p_{ij}
\right) ^{L}$
nur strikt positive
Elemente besitzt, das heißt 
$\forall (i, j) \in I^2 : p_{ij} > 0$
, wobei $I$ der Zustandsraum der
Markov-Kette ist, dann konvergieren (exponentiell schnell) die entsprechenden
Übergangswahrscheinlichkeiten 
$\left(
	p_{ij}
\right) ^{n}$
für $n \rightarrow \infty$ gegen von $i$ unabhängige Zahlen $p_{j}$ . Es
entsteht also eine stochastische Matrix mit identischen Zeilen. 
\\

Der entstandene
Wahrscheinlichkeitszeilenvektor $\rho$ ist eindeutig und löst das folgende Gleichungssystem:

\[
	\rho_k = \sum_{j \in I} \rho_j p_{jk} \quad (k \in I) \\
\] 
\[
	\rho = \rho \mathbb{P} \text{ mit } \mathbb{P} = (p_{ij})
\]

Man kann diese als einen Linkseigenvektor auffassen, der auch als invariante
Wahrscheinlichkeitsverteilung bezeichnet wird, weil das In- sowohl als auch Output gleichbleiben
bei Multiplikation mit der stochastischen Übergangsmatrix $\mathbb{P}$.

\subsubsection{Beweis von Satz 1}
Zunächst fixieren wir einen Spaltenvektor der Matrix $\mathbb{P}^{n}$ und suchen uns das minimale und das
maximale Element dieser Spalte aus:

\[
m_j ^{(n)} = \min_i p_{ij}^{(n)} \text{ und }
M_j^{(n)} = \max_i p_{ij}^{(n)}
\]

Dann gilt auch:

\begin{align*}
	m_j^{(n+1)} &= \min_i \sum_{h\in I} p_{ih} p_{hj} ^{(n)} \\
				&\geq \min_i \sum_{h\in I} p_{ih} m_{j} ^{(n)} \\
				&= m_j ^{(n)} \text{ und analog folgt auch } \\
				&\Rightarrow M_j ^{(n+1)} \leq M_j ^{(n)}
\end{align*}

Bei der ersten Gleichung wurde die Chapman-Kolmogorov-Gleichung genutzt und die zweite
Gleichung gilt, weil
$\sum_{h\in I} p_{ih} = 1$
ergibt (stochastische Matrix).

\subsubsection{Bemerkung}
$(m_j ^{(n)})_{n\in \mathbb{N}}$ bildet also eine monoton steigende und 
$(M_j ^{(n)})_{n \in \mathbb{N}}$
eine monoton fallende Folge in
$[0,1]$.
\\

Zusätzlich definieren wir ein $\delta$, dass das kleinste Element der Übergangsmatrix nach L-Zeitschritten
repräsentiert:
\[
p_{ij} ^{(L)} \geq \delta > 0, \quad
\forall (i, j) \in I^2
\] 

Darüber hinaus fixieren wir die Zeilen $h, j \in I$ und spalten alle
möglichen Zustände $k \in I$ wie folgt auf:
\[
k+ := \{
	k\in I \; \vert \; p_{hk} ^{(L)} \geq p_{ik} ^{(L)}
\} 
	\text{ und analog }
\] 
\[
k- := \{
	k\in I \; \vert \; p_{hk} ^{(L)} < p_{ik} ^{(L)}
\} \text{ , sodass gilt } (k+) \cup (k-) = I
\] 
Mittels der obigen Spaltung von $k$ in $k+$ und $k-$ folgt ein hilfreiches Resultat für die folgende Summen:

\[
\sum_{k+} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) + \sum_{k-} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) = 1 - 1 = 0
\] 

Nun betrachten wir nach (n+L)-Schritten für festes $n$ Element aus $\mathbb{Z}$ (ganze Zahlen) und $h$ Element
aus $I$ maximales Element $p_{hj} ^{n+L}$ und für $i$ Element aus $I$ das minimale Element $p_{ij} ^{n+L}$
Für diese gilt dann:

\begin{align*}
	M_j ^{(n+L)} - m_j ^{(n+L)} &= p_{hj} ^{(n+L)} - p_{ij} ^{(n+L)}
	= \sum_{k} \left(
		p_{hk} ^{(L)} - p_{ik} ^{(L)}
	\right) p_{kj} ^{(n)} \\
		& \leq \sum_{k+} \left(
			p_{hk} ^{(L)} - p_{ik} ^{(L)}
		\right) M_j ^{(n)} + \sum_{k-} \left(
			p_{hk} ^{(L)} - p_{ik} ^{(L)}
		\right) m_j ^{(n)} \\
		& \leq \sum_{k+} \left(
			p_{hk} ^{(L)} - p_{ik} ^{(L)}
		\right) \left(
			M_j ^{(n)} - m_j ^{(n)}
		\right) \\
		& \leq \left(
			1- \delta
		\right) \left(
			M_j ^{(n)} - m_j ^{(n)}
		\right) 
\end{align*}

In der ersten Ungleichung wird die Summe über alle $k$ in $k+$ und $k-$ zerlegt und die $p_{ kj }$ nach oben mit
$M_j$ bzw nach unten mit $m_j$ abgeschätzt. Mittels des umgeformten Hilfsresultates von oben

\[
\sum_{k+} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) 
=
-
\sum_{k-} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) 
\] 
erhält man die 2. Ungleichung,
Induktiv folgt nun

\[
M_j ^{(\nu L)} - m_j ^{(\nu L)}
\leq \left(
	1 - \delta
\right) ^{\nu} \quad (\nu \geq 0) .
\] 

Aufgrund der Bemerkung 1 ergibt sich folgende Abschätzung:
\[
	M_j ^{(n)} - m_j ^{(n)} \leq \left(
		1 - \delta
	\right) ^{(n-L) / L}
\]
Wobei $1- \delta$ Element aus $(0,1)$ ist und deshalb die Folge 
$\left(
	(1 - \delta) ^{(n-L) / L}
\right) _{n \in \mathbb{N}} $
für $n \rightarrow \infty$ gegen $0$
konvergiert. Das bedeutet, dass die Abstände zwischen kleinstem und größtem Element der $j$-ten
Spalte beliebig klein werden und diese somit gegen den gleichen Grenzwert $\rho_j$ konvergieren. Für
alle Elemente der $j$-ten Spalte gilt somit:

\[
	\; | \; p_{ij} ^{(n)} - \rho_j \; | \; \leq (1 - \delta) ^{(n-L) / L}
\]
Damit ist der erste Satz bewiesen.

\subsubsection{Beispiel 1 - Graph und Übergangsmatrix einer Markowkette}

\begin{center}
	\begin{tikzpicture}
		\tikzset{
			node distance=2cm,
		  }
		% Add the states
		\node[state]			 (c) {3};
		\node[state, below left=of c] (a) {1};
		\node[state, below right=of c] (b) {2};

		% Connect the states with arrows
		\draw[every loop]
			(a) edge[bend right, auto=right] node {0.75} (b)
			(b) edge[auto=right] node {0.5} (a)
			(b) edge[bend right, auto=right] node {0.5} (c)
			(c) edge[bend right, auto=right] node {1} (a)
			(a) edge[bend right, auto=left] node {0.25} (c)
	\end{tikzpicture}
\end{center}
\qquad \caption{\textbf{Abbildung 2.1.4:} Gerichteter Graph einer Markowkette, die Satz 1 erfüllt}
\\

Diese Markowkette hat folgende Übergangsmatrix:
\[
	\mathbb{P} = \begin{pmatrix} 
		0 & 0.75 & 0.25 \\
		0.5 & 0 & 0.5 \\
		1 & 0 & 0 \\
	\end{pmatrix} 
\]

Aus dem gerichteten Graphen ist die Fähigkeit zu erkennen, nach maximal 4 Schritten alle Zustände
zu erreichen.
Dies spiegelt sich auch in der $\mathbb{P} ^{4}$ Matrix wieder, für die gilt nämlich:

\[
	\mathbb{P} ^{4} \approx \begin{pmatrix} 
		0.39 & 0.28 & 0.33 \\
		0.5 & 0.23 & 0.27 \\
		0.37 & 0.47 & 0.16 \\
	\end{pmatrix} 
\]
Aufgrund der Gestalt dieser stochastischen Matrix sind alle Bedingungen des ersten Satzes erfüllt.
\\

Auf welche messbaren Eigenschaften der Markow-Ketten hat das Langzeitverhalten einen Einfluss?

Hierfür definieren wir zunächst wichtige Attribute der Zustände.

\section{Eigenschaften bezüglich Langzeitverhalten}

\subsection{Definition 16.3}

Wir sagen, dass Zustand $i$ in $n$ Schritten zu Zustand $j$ führe und schreiben
dafür $i \rightsquigarrow j [n] $, wenn $p_{ij} ^{(n)} > 0$ ist.
Gibt es ein $n \geq 1$ mit $i \rightsquigarrow j [n]$, so sagen wir $i$ führe
zu $j$ und schreiben $i \rightsquigarrow j$.
\\

Mit der Chapman-Kolmogorov-Gleichung folgt:
\[
p_{hj} ^{(m+n)} \geq p_{hi} ^{(m)} p_{ij} ^{(n)}
\] 
Aus dieser Gleichung folgt die Transitivität dieser Relation.

\subsubsection{Kommunizierende Zustände}

Der Zustand $i$ \textbf{kommuniziere}  mit $j$, hierfür schreiben wir
\[
i \leftrightsquigarrow j
\] 
wenn $i$ zu $j$ und umgekehrt $j$ zu $i$
führt.

\subsubsection{Wesentliche Zustände}
Der Zustand $i$ wird als \textbf{wesentlich}  bezeichnet, wenn dieser mit allen anderen Zuständen
kommuniziert, falls $i$ zu diesen Zuständen führt. Es gilt dabei die Umkehrung, also bilden alle
wesentlichen Zustände eine Äquivalenzrelation auf dem Zustandsraum des Prozesses, das heißt es
gilt zusätzlich die Reflexivität und Symmetrie.

\begin{center}
	\begin{tikzpicture}
		% Add the states
		\node[state]			 (a) {1};
		\node[state, right=of a] (b) {2};
		\node[state, right=of b] (c) {3};
		\node[state, right=of c] (d) {4};

		% Connect the states with arrows
		\draw[every loop]
			% a -> b -> c -> d
			(a) edge[bend right, auto=right] node {} (b)
			(c) edge[bend right, auto=right] node {} (d)

			% d -> c -> b -> a
			(d) edge[bend right, auto=right] node {} (c)
			(b) edge[bend right, auto=right] node {} (a)
			(c) edge[bend right, auto=right] node {} (b)

			% a -> a, b -> b, ...
			(a) edge[loop left]			     node {} (a)
			(d) edge[loop right]			 node {} (d)
	\end{tikzpicture}
\end{center}
\qquad \caption{\textbf{Abbildung 3.1.3:}  Die Zustände (1) und (2) sind wesentlich, (3) und (4) verletzen diese Eigenschaft.
}
\\

Eine weitere Problematik stellt die Periodizität der Markowketten dar. Im Folgenden untersuchen wir
dieses Phänomen genauer.

\subsection{Periodizität}

\subsubsection{Definition Periode}
Für einen Zustand $i$ mit $i \rightsquigarrow i$ heißt der grösste gemeinsame
Teiler der potenziellen Rückkehrzeiten
\[
d_i = \text{ggT} \{
	n \geq 1 : i \rightsquigarrow i [n]
\} 
\] 

die \textbf{Periode} von Zustand $i$. Falls $i$ mit sich selbst nicht kommuniziert, so ist die Periode unendlich.
Für d $i$ = 1 heißen die Zustände $i$ \textbf{aperiodisch} . Wenn jeder Zustand der Kette aperiodisch ist, so ist die
gesamte Markowkette aperiodisch. Die Fähigkeit aperiodisch zu sein ist eines der Anforderungen
für Markowketten die den Satz 1 erfüllen.

\subsection{Satz 2 - Kommunizierende Zustände haben die selbe Periode}
Kommuniziert $i$ mit $j$, so gilt $d_i = d_j$

\subsubsection{Beweis von Satz 2}
\begin{proof}
Zunächst zeigen wir $d_i \leq d_j$ woraus aus Symmetriegründen der Korrespondenz auch die
Umkehrung gilt:
\\

	\begin{enumerate}
		\item Gilt $j \rightsquigarrow j[n]$ und sind $k, m$ Zeitpunkte mit 
			$i \rightsquigarrow j [k]$ und $j \rightsquigarrow i [m]$, so gilt
		\item $i \rightsquigarrow i [k+m]$ und $i \rightsquigarrow i [k+m+n]$.
		\item $d_i$ teilt also $k+m$ und $k+m+n$ und also auch $n$. 
		\item $d_i$ ist also gemeinsamer Teiler aller $n$ mit 
			$j \rightsquigarrow j [n]$. 
		\item Daraus folgt, dass $d_i \leq d_j$ ist.
	\end{enumerate}
\end{proof}
\\

Jetzt folgt eine nützliche Partition auf der Menge der Zustände, die zu sich zurückführen, durch diese
Relation.

\subsubsection{Unterteilung periodischer Markowketten in Restklassen}

Die entstandene Äquivalenzrelation unterteilt also alle möglichen Zustände in
Repräsentanten, für die alle Elemente aus dieser Repräsentantenmenge gilt, dass alle Zustände mit
einander kommunizieren.
\\

Eine solche Äquivalenzklasse bezeichnen wir mit $C(i)$, d.h. falls $i \leftrightsquigarrow j$ gilt, so ist $C(i)=C(j)$.

Zum Beispiel gilt in Abbildung 3.1.3 Folgendes: 
\[
	C(1) = C(2) \text{ und } C(3) = C(4)
\] 
wobei $C (3)$ ein nicht wesentlicher
Zustand ist, man kann also diesen „für immer“ verlassen.
\\

\subsubsection{Bemerkung}
Die Periode einer dieser Äquivalenzklassen ist die Periode jedes Elementes dieser Menge, sie ist für alle
Elemente gleich.
Durch diese Partition der Zustände ist es nun bei der Betrachtung der Perioden $d_i$ , für ein beliebiges $i$
Element aus $I$, der jeweiligen Äquivalenzklassen $[i]$ bzw. $C([i])$ möglich festzustellen, dass die
Zyklen, falls $d_i \geq 2$ gilt, von deterministischer Natur sind.
\\

An dieser Stelle wurde im Buch der Beweis zu folgendem Lemma dargestellt:

\subsubsection{Lemma 16.6}
Ist $d$ der grösste gemeinsame Teiler von Zahlen $n_1, n_2, ... \in \mathbb{N}$,
so gibt es Zahlen $K$ und $L$ derart, dass sich jedes $ld$ mit $l \geq L$
als Summe der Form
\[
ld = \sum_{k=1}^{K} c_k n_k \qquad
\text{ mit } c_k \in \mathbb{N}
\] 
schreiben lässt.
\\

Den Beweis hierfür sparen wir uns und setzen fort mit der Periode von $C(i)$, indem wir den dritten Satz einführen.

\subsection{Satz 3}

Zu jedem Element $j$ der Äquivalenzklasse $C([i])$ existiert eine eindeutig bestimmte Zahl $r(j)$ mit
$0 \leq r(j) < d_i$ derart, dass $i$ zu $j$ in $n$ Schritten führe, nur für solche $n$, für die gilt:
$n \equiv r(j) (\text{mod } d_i)$, für hinreichend großes $n>N(j)$ auch für alle diese $n$. 
\\

Das heißt, dass es Zeitpunkte
gibt, in denen bestimmte Zustände aktuell nicht erreichbar sind.

\subsubsection{Beweis von Satz 3}

\begin{proof}
	Es gibt ein $k$ mit $j \rightsquigarrow i [k]$.
	\\

	Sind $m<n$ zwei natürliche Zahlen mit $i \rightsquigarrow j[m]$ und
	$i \rightsquigarrow j[n]$, so gilt
	$i \rightsquigarrow i[k+m]$ und $i \rightsquigarrow i[k+n]$.

	$d_i$ teilt also $n - m$. Alle $n$ mit $j \rightsquigarrow j[n]$ liegen also
	in der gleichen Restklassen $r_j \; (\text{mod } d_i)$.
	\\

	Für ein $m \geq 0$ gilt also $i \rightsquigarrow j[m d_i + r_j]$.

	Ist $L$ die zu $d = d_i$ im vorigen Lemma bestimmte Zahl, so setzt man
	$N(j) = r_j + m d_i + L d_i$.
	\\

	Für jedes $n \equiv r_j \; (\text{mod } d_i)$ mit $n \geq N(j)$ gibt
	es dann ein $l \geq L$ mit $n = r_j + m d_i + l d_i$.

	Aus $i \rightsquigarrow i[n_k]$ und (16.7) folgt $i \rightsquigarrow i [l d_i]$
	und also $i \rightsquigarrow j[n]$.
\end{proof}


\subsubsection{Resultate des Satzes}
Um solche unerwünschten Szenarien zu vermeiden, konzentrieren wir uns nur noch auf die
aperiodischen Markowketten bei denen alle Zustände miteinander kommunizieren und $n > N(j)$ ist.
\\

Diese Bedingungen erfüllen die strikte Positivität der Elemente $p_{ij} ^{(n)}$, womit Satz 1 gilt.
Umgekehrt bedeutet das, wenn alle $p_{ij} ^{(n)} > 0$, dass alle Zustände miteinander kommunizieren und der
Prozess aperiodisch ist.
\\

Denn erstens gilt $i \rightsquigarrow i[n]$ und zweitens $i \rightsquigarrow i[n+1]$,
weil nämlich für mindestens ein $j \in I$

\begin{itemize}
	\item $i \rightsquigarrow j[1]$ und für alle $j \in I$
	\item $j \rightsquigarrow i[n]$
\end{itemize}

gilt.

\section{Rückkehrverhalten von Markowketten}

Für das wahrscheinlichkeitstheoretische Verhalten der Markowketten ist es essentiell zu wissen, ob man
zum Ausgangszustand mit einer Wahrscheinlichkeit von $1$ zurückkehrt. Diese Abhängigkeit vom System
veranlasst uns das Rückkehrverhalten des Prozesses zu studieren.

\subsection{Wichtige Definitionen zur Beschreibung des Rückkehrverhaltens}

Wir beginnen deshalb mit folgender Definition:
\[
f_{ij} ^{(n)} := P_i \left(
	X_n = j, X_{n-1} \ne j, ..., X_2 \ne j, X_1 \ne j
\right) 
\] 
ist die Wahrscheinlichkeit nach genau $n$ Schritten beim Start in $i$ das erste Mal den Zustand $j$ zu erreichen.
\\

Dieses eingeführte Ereignis ist alleine nicht vielversprechend, weshalb wir die Summe dieser Größe über
alle $n$ Element aus den Natürlichen Zahlen bilden.

\[
f_{ij} ^{*} := \sum_{n=1}^{\infty} f_{ij} ^{(n)}
\] 

Somit ist dies die Wahrscheinlichkeit bei Start in $i$ je nach $j$ zu gelangen.
\\

Zusätzlich wird die erwartete Anzahl der Besuche in $j$ bei Start in $i$ folgendermaßen definiert:

\begin{align*}
	p_{ij} ^{*} &=
	\sum_{n=1}^{\infty} p_{ij} ^{(n)} 
				= \sum_{n=1}^{\infty} E_i \left[
		1_{\{
				X_n = j
		\}}  
	\right] 
			  = E_i \left[
				  \sum_{n=1}^{\infty} 1\{
				  	X_n = j
				  \} 
			  \right]  \\
			  &= E_i \left[
				  \text{Anzahl $B_j$ der Besuche in $j$ zu Zeitpunkten $n \geq 1$}
			  \right] 
\end{align*}

Dabei bezeichnet $E_i$ den Erwartungswert unter $P_i$, also bei Start in $i$.

\subsubsection{Definition Stoppzeit}
Eine Zufallsvariable 
\[
\tau : \Omega \mapsto \{
	0, 1, 2, ..., \infty
\} 
\] 
heißt \textbf{Stoppzeit} , wenn für alle $n \geq 0$ das Ereignis 
\[
\{
	\omega \in \Omega \; \vert \; \tau (\omega) = n
\} 
\] 
nur von $X_0, X_1 ,...,X_n$ abhängt. Das bedeutet, 
dass für ein geeignetes $A \subset I ^{n+1}$
\[
\{
	\tau = n
\} = \{
	\left(
		X_0, ..., X_n
	\right) \in A
\}
\] 

\subsection{Satz 4}

Es gilt $P_i(B_i \geq m) = \left(
	f_{ii} ^{*}
\right) ^{m}$ für $m \geq 1$.

Dabei ist $B_i$ die Anzahl der Besuche in Zustand $i$.

\subsubsection{Beweis von Satz 4}
\begin{proof}
	Sei 
	\[
	\tau_1 = \inf \{
		n \geq 1 : X_n (\omega) = i
	\} 
	\] 
	der früheste Zeitpunkt des Eintretens des Zustandes $i$ nach einem Schritt
	und 
	\[
		\tau_{m+1} (\omega) = \inf \{
			n > \tau_{m} : X_n (\omega) = i
		\} 
	\] 
	der Zeitpunkt, an dem Zustand $i$ zum $(m+1)$-ten Mal besucht wird. Das Infimum
	der leeren Menge ist dabei $\infty$, sowie $\tau_m (\omega)$, wenn der Zustand i nicht $m$-mal besucht werden kann.
	\\

	Nun zum Beweis, der mittels einer Induktion über $m \in \mathbb{N}$ folgt:

	Sei $m=1$ dann gilt,
	\[
		P_i (B_i \geq m) = P_i (\tau_m < \infty)
		= f_{ii} ^{*},
	\] 
	da $f_{ii} ^{*}$ die Rückkehrwahrscheinlichkeit nach $i$ ist.
	\\

	Induktionsschritt: Sei nun die Behauptung für ein $m$ wahr. Wir zeigen mit Hilfe der Menge
	\[
	D_n ^{n+k} = \{
		X_{n+1} \ne i, ..., X_{n+k-1} \ne i, X_{n+k} = i
	\},
	\] 
	dass dies dann auch für $m+1$ gilt:
	\begin{align*}
		P_i (\tau_{m+1} < \infty) &= 
		\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} 
		P_i \left(
			\tau_{m+1} - \tau_m = k, \tau_m = n
		\right) \\
			  &= 
		\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} 
		P_i \left(
			\tau_{m+1} - \tau_m = k \; \vert \; \tau_m = n
		\right) P_i \left(
			\tau_m = n
		\right) \\
			  &=
		\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} 
		P_i \left(
			D_n ^{n+k} \; \vert \; X_n = i, \left(
				X_0, ..., X_{n-1}
			\right) \in A_{mn}
		\right) P_i \left(
			\tau_m = n
		\right) \\
			  &= 
		\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} 
		P_i \left(
			D_n ^{n+k} \; \vert \; X_n = i
		\right) P_i \left(
			\tau_m = n
		\right) \\
			  &= 
		\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} 
		P_i \left(
			D_0 ^{k} \; \vert \; X_0 = i
		\right) P_i \left(
			\tau_m = n
		\right) \\
			  &=
		\sum_{k=1}^{\infty}
		f_{ii} ^{(k)}
		P_i \left(
			\tau_m < \infty
		\right) \\
			  &= f_{ii} ^{*} \left(
			  	f_{ii} ^{*}
			  \right) ^{m}
	\end{align*}
	Die erste Gleichung erklärt sich durch das Betrachten der Sprünge zwischen dem Eintreten des
	$n$-ten Zeitpunktes und dem darauffolgenden, wobei $n$ alle natürlichen Zahlen durchläuft.
	\\

	In der zweiten Gleichung nutzen wir die bedingte Wahrscheinlichkeit und können somit für die
	Sprünge zwischen $n$ und $n+k$ die Menge $D_n ^{n+k}$ nutzen, die vom Ereignis $A_{mn}$ unabhängig ist.
	Aufgrund der Homogenität des Prozesses gelangen wir schließlich zur letzten Gleichung, die die
	Induktion, und damit den Beweis, abschließt.
	\\

\end{proof}


\subsection{Rekurrenz und Transienz}
Nach dem Beweis des letzten Satzes ist es uns möglich die Begriffe Rekurrenz und Transienz
einzuführen und zu studieren.

\subsubsection{Bemerkung}

Statt $P_i (B_i = \infty)$ schreiben wir auch
$\{
	X_n = i \; \infty \; \text{oft}
\} $

\subsubsection{Definition Rekurrenz und Transienz}
Ein Zustand i heißt \textbf{rekurrent} , wenn 
\[
P_i \left(
	X_n = i \; \infty \; \text{oft}
\right) = 1 
\] 
ist, das heißt dieser Zustand $i$ wird fast
sicher unendlich oft durchlaufen. Andernfalls heißt $i$ transient und die Markowkette heißt dann
rekurrent bzw. transient, wenn jeder Zustand rekurrent bzw. transient ist.

\subsection{Satz 5 - Rekurrenzsatz}
Ein Zustand $i$ ist rekurrent genau dann, wenn $f_{ii}^* = 1$ ist.

Hierfür notwendig und auch hinreichend ist $p_{ii} ^{*} = \infty$.
\\

Wir müssen also nur prüfen ob die Summe 
$p_{ii} ^{*} = \sum_{n=1}^{\infty} p_{ii} ^{(n)}$
konvergiert oder divergiert. Wollen wir Rekurrenz zeigen, müssen wir sogar nur
zeigen, dass die Summanden $p_{ii} ^{(n)}$ nicht gegen $0$ konvergieren.

\subsubsection{Beweis von Satz 5}

\begin{proof}
	"$\Leftarrow$"

	Sei also $f_{ii} ^{*} =1$, so ist nach Satz 4 auch 
	$P_i \left(
		B_i \geq m
	\right) = 1$
	für alle $m \geq 1$ und deshalb 
	$P_i \left(
		B_i = \infty
	\right) = 1 ^{\infty} = 1$,
	was $i$ zu einem rekurrenten Zustand macht. 
	Somit gilt auch für die Erwartung von $B_i$, $p_{ii} ^{*} = \infty$.
	\\

	"$\Rightarrow$"

	Hier nutzen wir die Tautologie der Implikation 
	\[
	\left(
		A \Rightarrow B
	\right) \Leftrightarrow 
	\left(
		\neg B \Rightarrow \neg A
	\right) 
	\] 
	und gehen deshalb
	davon aus, dass $f_{ii} ^{*} < 1$ gilt. Dann gilt die Konvergenz der folgenden geometrischen Reihe:
	\[
	\sum_{m=1}^{\infty} P_i \left(
		B_i \geq m
	\right) = \sum_{m=1}^{\infty} \left(
		f_{ii} ^{*}
	\right) ^{m} < \infty
	\] 
	Dies wiederum bedeutet, dass $P_i (B_i = \infty) = 0$, also fast unmöglich gilt.
	\\

	Es sei $k$ die endliche Anzahl der Besuche in $i$, dann kommt in der linken Summe $P_i \left(
		B_i = k
	\right) $ $k$-mal
	vor, für $m=1,...,k$. Es ist also die Erwartung $p_{ii} ^{*}$ von $B_i$ unter $P_i$ und es gilt $p_{ii} ^{*} < \infty$.
\end{proof}

\subsection{Rekurrenzkriterium und Folgerungen aus Rekurrenz}
Diese zusätzlich definierte, notwendige und hinreichende Bedingung der Rekurrenz, $p_{ii} ^{*} = \infty$, ist
sehr hilfreich. Sie wird auch als Rekurrenzkriterium bezeichnet. 
Um jenes zu zeigen, reichen
Abschätzungen von Wahrscheinlichkeiten. 
\\

Für den direkten Weg, also zeigen, dass $f_{ii} ^{*} = 1$ gilt,
müsste man unendlich viele $f_{ii} ^{(n)}$ berechnen.

\subsubsection{Folgerungen aus Rekurrenz}
Folgende Folgerungen aus der Rekurrenz sind nützlich:

\begin{enumerate}
	\item Alle mit einem rekurrenten Zustand kommunizierenden Zustände sind rekurrent.
	\item Ist $i$ rekurrent, so gilt für alle $j$ mit 
		$i \rightsquigarrow j$, $f_{ji} ^{*} = 1$
		. Insbesondere ist jeder rekurrente Zustand wesentlich.
\end{enumerate}

\begin{proof}
	Zu 1.
	\\

	Seien $p_{ji} ^{(k)} > 0, p_{ij} ^{(m)} > 0$ und 
	$p_{ii} ^{*} = \infty$. Per Definition gilt
	\[
	p_{ii} ^{*} = \sum_{n=1}^{\infty} p_{ii} ^{(n)}
	\] 
	Zusätzlich gilt folgende Abschätzung 
	\[
	p_{jj} ^{(k+n+m)} \geq p_{ji} ^{(k)}
	p_{ii} ^{(n)} p_{ij} ^{(m)}
	\] 
	(nach Chapman-Kolmogorow-Gleichung).
	Es folgt daraus durch Summation $p_{jj} ^{*} = \infty$
\end{proof}

\begin{proof}
	Zu 2.
	\\
	
	Wegen $i \rightsquigarrow j$ existiert ein $m$ mit $p_{ij} ^{(m)} > 0$.
	Da $i$ rekurrent ist, gilt
	\begin{align*}
		1 &= P_i \left(
			\exists n > m : X_n = i
		\right) \\
		  &= \sum_{k \in I} P_i \left(
		  	\exists n > m: X_n = i, X_m = k
		  \right) \\
		  &= \sum_{k \in I}
		  P_i (X_m = k)
		  P_i \left(
		  	\exists n > m: X_n = i \; \vert \; X_m = k
		  \right) \\
		  &= \sum_{k \in I}
		  p_{ik} ^{(m)}
		  P_k \left(
		  	\exists n > 0: X_n = i
		  \right) \\
		  &= \sum_{k \in I}
		  p_{ik} ^{(m)}
		  f_{ki} ^{*}
	\end{align*}
	Wäre $f_{ij} ^{*} < 1$, so wäre die letzte Summe $<1$.
	\\

	Die zweite Gleichung erfolgt über die Chapman-Kolmogorow-Gleichung und die dritte über die
	bedingte Wahrscheinlichkeit mit $P(A \; \cap \; B) = P(A \; \vert \; B) P(B)$
	(Satz von Bayes). Anschließend nutzen wir die
	Homogenität der Markowkette und gelangen zu der letzten Gleichung.
\end{proof}

\section{Quellen}

\begin{itemize}
	\item Ulrich Krengel - Einführung in die Wahrscheinlichkeitstheorie und Statistik - 8. Auflage 

		Kapitel 16 - "Das Verhalten markowscher Ketten in langen Zeiträumen"
\end{itemize}

\end{document}
