\documentclass[a4paper]{article}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
\usepackage[german]{babel}

\usepackage{tikz}
\usetikzlibrary{automata, positioning}

\pdfminorversion=7
\pdfsuppresswarningpagegroup=1

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\beh}{\textit{Behauptung. }}

\setlength{\parindent}{0pt}

\begin{document}

\begin{titlepage}
   \begin{center}
       \vspace*{1cm}

       \textbf{Ausarbeitung Proseminar}

       \vspace{0.5cm}
	   \section*{
		   Langzeitverhalten von Markowketten
	   }
            
       \vspace{1.5cm}

	   \textbf{Nogarbek Sharykpayev (6870965),\\ Bent Müller (7302332)}

       \vfill
            
       \vspace{0.8cm}
     
            
       Fachbereich Mathematik\\
       Universität Hamburg\\
       Deutschland\\
       17.08.2021
            
   \end{center}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak

\section{Kleine Wiederholung - Markowketten}

Bevor wir uns mit dem Langzeitverhalten der Markow-Ketten beschäftigen, folgt hier eine kleine Wiederholung:
\\

Der aktuelle Zustand einer Markow-Kette besitzt die Eigenschaft von Zuständen aus mindestens 2 Schritten aus der Vergangenheit unabhängig zu sein, also wenn gilt:

\subsection{Markowsche Eigenschaft}

1. Es sei $\{X_n : n \in \mathbb{Z} \}$ ein stochastischer Prozess mit dem abzählbaren Zustandsraum $I$ und es gilt für alle $i_0, …, i_{n+1}$ Element in $I$ : 

\[
	P(X_0 = i_0, ..., X_{n} = i_{n}) > 0 \\
\] 

\[
	P(X_{n+1} = i_{n+1} \; \vert \; X_0 = i_0, ..., X_{n} = i_{n})
	= 
	P(X_{n+1} = i_{n+1} \; \vert \; X_{n} = i_{n})

\] 


dann besitzt dieser stochastische Prozess die markowsche Eigenschaft und ist somit eine Markow-Kette

\subsection{Stationäre Übergangswahrscheinlichkeiten und stochastische Matrix}

2. Eine homogene Markov-Kette besitzt stationäre Übergangswahrscheinlichkeiten. Das bedeutet:

\[
	\forall i, j \in I: P(X_{n+1} = j \; \vert \; X_n = i) =: p_{ij}
\] 
Der Prozess ist damit unabhängig von $n$.
\\

Mit der letzten Eigenschaft lassen sich solche stochastischen Prozesse mittels folgender Gleichung
modellieren:

\[
	\mathbb{P} ^{n} x_0 = x_n
\] 

$\mathbb{P}$ : stochastische Matrix, die einen Markow-Prozess genau nach einem Schritt/Übergang beschreibt.

\begin{align*}
	\mathbb{P} = \left(
		p_{ij}
	\right) \text{ ist stochastische Matrix } & \Leftrightarrow \\
	p_{ij} \geq 0 \left(
		i, j \in I
	\right) \text{ und }
	\sum_{j \in I} p_{ij} = 1
\end{align*}

$x_0$ : Die Startverteilung (z.B. (1, 0,…,0) , der Prozess startet in dem ersten Zustand ) \\
$n$ : Anzahl der Schritte/Übergänge ( Zeitdiskretes Modell) \\
$x_n$ : Die Verteilung nach n-Übergängen (kein deterministischer Faktor mehr). \\

Nun zu der Leitfrage dieses Kapitels: Welche qualitativen Eigenschaften der Markow-Ketten haben
Einfluss auf das Langzeitverhalten des Prozesses. Die obere explizite Darstellung der Folge
$(X_n)_{n\in \mathbb{N}}$ zeigt die Wichtigkeit der Analyse der stochastischen Matrix. Was muss also für diese
Matrix P gelten, damit sie für $n \rightarrow \infty$ konvergiert ? Dies beantwortet der folgende Satz:

\section{Langzeitverhalten}

\subsection{Satz 1 - Konvergenz der Übergangsmatrix}

Unter der Voraussetzung, dass die L-Schritt-Übergangsmatrix 
$\mathbb{P} ^{L} = \left(
	p_{ij}
\right) ^{L}$
nur strikt positive
Elemente besitzt, das heißt 
$\forall (i, j) \in I^2 : p_{ij} > 0$
, wobei $I$ der Zustandsraum der
Markov-Kette ist, dann konvergieren (exponentiell schnell) die entsprechenden
Übergangswahrscheinlichkeiten 
$\left(
	p_{ij}
\right) ^{n}$
für $n \rightarrow \infty$ gegen von $i$ unabhängige Zahlen $p_{j}$ . Es
entsteht also eine stochastische Matrix mit identischen Zeilen. 
\\

Der entstandene
Wahrscheinlichkeitszeilenvektor $\rho$ ist eindeutig und löst das folgende Gleichungssystem:

\[
	\rho_k = \sum_{j \in I} \rho_j p_{jk} \quad (k \in I) \\
\] 
\[
	\rho = \rho \mathbb{P} \text{ mit } \mathbb{P} = (p_{ij})
\]

Man kann diese als einen Linkseigenvektor auffassen, der auch als invariante
Wahrscheinlichkeitsverteilung bezeichnet wird, weil das In- sowohl als auch Output gleichbleiben
bei Multiplikation mit der stochastischen Übergangsmatrix $\mathbb{P}$.

\subsubsection{Beweis von Satz 1}
Zunächst fixieren wir einen Spaltenvektor der Matrix $\mathbb{P}^{n}$ und suchen uns das minimale und das
maximale Element dieser Spalte aus:

\[
m_j ^{(n)} = \min_i p_{ij}^{(n)} \text{ und }
M_j^{(n)} = \max_i p_{ij}^{(n)}
\]

Dann gilt auch:

\begin{align*}
	m_j^{(n+1)} &= \min_i \sum_{h\in I} p_{ih} p_{hj} ^{(n)} \\
				&\geq \min_i \sum_{h\in I} p_{ih} m_{j} ^{(n)} \\
				&= m_j ^{(n)} \text{ und analog folgt auch } \\
				&\Rightarrow M_j ^{(n+1)} \leq M_j ^{(n)}
\end{align*}

Bei der ersten Gleichung wurde die Chapman-Kolmogorov-Gleichung genutzt und die zweite
Gleichung gilt, weil
$\sum_{h\in I} p_{ih} = 1$
ergibt (stochastische Matrix).

\subsubsection{Bemerkung 1}
$(m_j ^{(n)})_{n\in \mathbb{N}}$ bildet also eine monoton steigende und 
$(M_j ^{(n)})_{n \in \mathbb{N}}$
eine monoton fallende Folge in
$[0,1]$.
\\

Zusätzlich definieren wir ein $\delta$, dass das kleinste Element der Übergangsmatrix nach L-Zeitschritten
repräsentiert:
\[
p_{ij} ^{(L)} \geq \delta > 0, \quad
\forall (i, j) \in I^2
\] 

Darüber hinaus fixieren wir die Zeilen $h, j \in I$ und spalten alle
möglichen Zustände $k \in I$ wie folgt auf:
\[
k+ := \{
	k\in I \; \vert \; p_{hk} ^{(L)} \geq p_{ik} ^{(L)}
\} 
	\text{ und analog }
\] 
\[
k- := \{
	k\in I \; \vert \; p_{hk} ^{(L)} < p_{ik} ^{(L)}
\} \text{ , sodass gilt } (k+) \cup (k-) = I
\] 
Mittels der obigen Spaltung von $k$ in $k+$ und $k-$ folgt ein hilfreiches Resultat für die folgende Summen:

\[
\sum_{k+} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) + \sum_{k-} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) = 1 - 1 = 0
\] 

Nun betrachten wir nach (n+L)-Schritten für festes $n$ Element aus $\mathbb{Z}$ (ganze Zahlen) und $h$ Element
aus $I$ maximales Element $p_{hj} ^{n+L}$ und für $i$ Element aus $I$ das minimale Element $p_{ij} ^{n+L}$
Für diese gilt dann:

\begin{align*}
	M_j ^{(n+L)} - m_j ^{(n+L)} &= p_{hj} ^{(n+L)} - p_{ij} ^{(n+L)}
	= \sum_{k} \left(
		p_{hk} ^{(L)} - p_{ik} ^{(L)}
	\right) p_{kj} ^{(n)} \\
		& \leq \sum_{k+} \left(
			p_{hk} ^{(L)} - p_{ik} ^{(L)}
		\right) M_j ^{(n)} + \sum_{k-} \left(
			p_{hk} ^{(L)} - p_{ik} ^{(L)}
		\right) m_j ^{(n)} \\
		& \leq \sum_{k+} \left(
			p_{hk} ^{(L)} - p_{ik} ^{(L)}
		\right) \left(
			M_j ^{(n)} - m_j ^{(n)}
		\right) \\
		& \leq \left(
			1- \delta
		\right) \left(
			M_j ^{(n)} - m_j ^{(n)}
		\right) 
\end{align*}

In der ersten Ungleichung wird die Summe über alle $k$ in $k+$ und $k-$ zerlegt und die $p_{ kj }$ nach oben mit
$M_j$ bzw nach unten mit $m_j$ abgeschätzt. Mittels des umgeformten Hilfsresultates von oben

\[
\sum_{k+} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) 
=
-
\sum_{k-} \left(
	p_{hk} ^{(L)} - p_{ik} ^{(L)}
\right) 
\] 
erhält man die 2. Ungleichung,
Induktiv folgt nun

\[
M_j ^{(\nu L)} - m_j ^{(\nu L)}
\leq \left(
	1 - \delta
\right) ^{\nu} \quad (\nu \geq 0) .
\] 

Aufgrund der Bemerkung 1 ergibt sich folgende Abschätzung:
\[
	M_j ^{(n)} - m_j ^{(n)} \leq \left(
		1 - \delta
	\right) ^{(n-L) / L}
\]
Wobei $1- \delta$ Element aus $(0,1)$ ist und deshalb die Folge 
$\left(
	(1 - \delta) ^{(n-L) / L}
\right) _{n \in \mathbb{N}} $
für $n \rightarrow \infty$ gegen $0$
konvergiert. Das bedeutet, dass die Abstände zwischen kleinstem und größtem Element der $j$-ten
Spalte beliebig klein werden und diese somit gegen den gleichen Grenzwert $\rho_j$ konvergieren. Für
alle Elemente der $j$-ten Spalte gilt somit:

\[
	\; | \; p_{ij} ^{(n)} - \rho_j \; | \; \leq (1 - \delta) ^{(n-L) / L}
\]
Damit ist der erste Satz bewiesen.

\subsubsection{Beispiel 1 - Graph und Übergangsmatrix einer Markowkette}

\begin{center}
	\begin{tikzpicture}
		\tikzset{
			node distance=2cm,
		  }
		% Add the states
		\node[state]			 (c) {3};
		\node[state, below left=of c] (a) {1};
		\node[state, below right=of c] (b) {2};

		% Connect the states with arrows
		\draw[every loop]
			(a) edge[bend right, auto=right] node {0.75} (b)
			(b) edge[auto=right] node {0.5} (a)
			(b) edge[bend right, auto=right] node {0.5} (c)
			(c) edge[bend right, auto=right] node {1} (a)
			(a) edge[bend right, auto=left] node {0.25} (c)
	\end{tikzpicture}
\end{center}
\qquad \caption{\textbf{Abbildung 2.1.4:} Gerichteter Graph einer Markowkette, die Satz 1 erfüllt}
\\

Diese Markowkette hat folgende Übergangsmatrix:
\[
	\mathbb{P} = \begin{pmatrix} 
		0 & 0.75 & 0.25 \\
		0.5 & 0 & 0.5 \\
		1 & 0 & 0 \\
	\end{pmatrix} 
\]

Aus dem gerichteten Graphen ist die Fähigkeit zu erkennen, nach maximal 4 Schritten alle Zustände
zu erreichen.
Dies spiegelt sich auch in der $\mathbb{P} ^{4}$ Matrix wieder, für die gilt nämlich:

\[
	\mathbb{P} ^{4} \approx \begin{pmatrix} 
		0.39 & 0.28 & 0.33 \\
		0.5 & 0.23 & 0.27 \\
		0.37 & 0.47 & 0.16 \\
	\end{pmatrix} 
\]
Aufgrund der Gestalt dieser stochastischen Matrix sind alle Bedingungen des ersten Satzes erfüllt.
\\

Auf welche messbaren Eigenschaften der Markow-Ketten hat das Langzeitverhalten einen Einfluss?

Hierfür definieren wir zunächst wichtige Attribute der Zustände.

\section{Eigenschaften bezüglich Langzeitverhalten}

\subsection{Definition 16.3}

Wir sagen, dass Zustand $i$ in $n$ Schritten zu Zustand $j$ führe und schreiben
dafür $i \rightsquigarrow j [n] $, wenn $p_{ij} ^{(n)} > 0$ ist.
Gibt es ein $n \geq 1$ mit $i \rightsquigarrow j [n]$, so sagen wir $i$ führe
zu $j$ und schreiben $i \rightsquigarrow j$.
\\

Mit der Chapman-Kolmogorov-Gleichung folgt:
\[
p_{hj} ^{(m+n)} \geq p_{hi} ^{(m)} p_{ij} ^{(n)}
\] 
Aus dieser Gleichung folgt die Transitivität dieser Relation.

\subsubsection{Kommunizierende Zustände}

Der Zustand $i$ kommuniziere mit $j$, hierfür schreiben wir
\[
i \leftrightsquigarrow j
\] 
wenn $i$ zu $j$ und umgekehrt $j$ zu $i$
führt.

\subsubsection{Wesentliche Zustände}
Der Zustand $i$ wird als wesentlich bezeichnet, wenn dieser mit allen anderen Zuständen
kommuniziert, falls $i$ zu diesen Zuständen führt. Es gilt dabei die Umkehrung, also bilden alle
wesentlichen Zustände eine Äquivalenzrelation auf dem Zustandsraum des Prozesses, das heißt es
gilt zusätzlich die Reflexivität und Symmetrie.

\end{document}
